{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673a54a2-c9bf-4f16-8987-c527fb6a267b",
   "metadata": {},
   "source": [
    "# STAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233070b-8c99-42c2-abbe-cbceb285da4f",
   "metadata": {},
   "source": [
    "## stackstac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffc93b",
   "metadata": {},
   "source": [
    "## Cloud-Optimized GeoTIFF (COG) STAC Catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f6dedd",
   "metadata": {},
   "source": [
    "### Earth Search by Element 84 Catalogs by Sensor or Organization\n",
    "<!-- 1. Sentinel\n",
    "    - [Sentinel-2 Pre-Collection 1 Level-2A](https://stacindex.org/catalogs/earth-search#/WYEJqXnNPKBm6QrPX82kX2Q894FF8MQ3BzoXBFBzdbmeY?t=3):\n",
    "    - [Sentinel-2 Level-2A](https://stacindex.org/catalogs/earth-search#/43bjKKcJQfxYaT1ir3Ep6uENfjEoQrjkzhd2?t=3)\n",
    "    - [Sentinel-2 Level-1C](https://stacindex.org/catalogs/earth-search#/43bjKKcJQfxYaT1ir3Ep6uENfjEoQrjkzhYe?t=3)\n",
    "    - [Sentinel-2 Collection 1 Level-2A](https://stacindex.org/catalogs/earth-search#/5WpJuuvfexLDmorjkAGQ8X6oLkYtawu8NG3NGezU?t=3) -->\n",
    "<!-- 6. [China-Brazil Earth Resources Satellite (CBERS)](https://stacindex.org/catalogs/cbers) ([AWS link](https://registry.opendata.aws/cbers/)) -->\n",
    "<!-- for future reference: -->\n",
    "<!-- https://registry.opendata.aws/openaerialmap/ -->\n",
    "<!-- https://registry.opendata.aws/pgc-earthdem/ -->\n",
    "<!-- https://registry.opendata.aws/seefar/ https://coastalcarbon.ai/seefar -->\n",
    "\n",
    "\n",
    "1. **Maxar Open Data**\n",
    "    - [STAC index](https://stacindex.org/catalogs/maxar-open-data-catalog-ard-format#/) | ([AWS link](https://registry.opendata.aws/maxar-open-data/))\n",
    "2. **Harmonized Landsat and Sentinel-2 (HLS)**\n",
    "    - Sentinel data: [MS Planetary Computer](https://planetarycomputer.microsoft.com/dataset/hls2-s30) \n",
    "    - Landsat data: [MS Planetary Computer](https://planetarycomputer.microsoft.com/dataset/hls2-l30)\n",
    "3. [Earthview dataset](https://satellogic-earthview.s3.us-west-2.amazonaws.com/index.html#data_access)([AWS link](https://registry.opendata.aws/satellogic-earthview/))\n",
    "4. NAIP: National Agriculture Imagery Program\n",
    "    - [STAC index](https://stacindex.org/catalogs/earth-search#/DHAWSgxTJP2jRyydLqfVMh?t=3) ([AWS link](https://registry.opendata.aws/naip/))\n",
    "\n",
    "5. Planet Labs\n",
    "    - SpaceNet7 STAC collection: [STAC index](https://www.planet.com/data/stac/browser/spacenet7/catalog.json?.language=en) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f1f27-037b-44ca-bca8-f5f51364d969",
   "metadata": {},
   "source": [
    "### Maxar Open Data STAC Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce8c050-4194-46ed-b03b-325a24184e2f",
   "metadata": {},
   "source": [
    "## Save matching STAC items as hive partitioned geoparquets\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4917f6-3528-4993-949f-566236ad4adb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def div_to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264645c1-d6da-4a58-a110-3fa4770cb637",
   "metadata": {},
   "source": [
    "## Use Cubo to fetch STAC assets at coordinate point\n",
    "\n",
    "[cubo](https://cubo.readthedocs.io/en/latest/index.html) is a Python library for working with STAC (SpatioTemporal Asset Catalog) collections and fetching samples from them. It provides a convenient way to interact with STAC APIs and retrieve geospatial data.\n",
    "\n",
    "Look into managing raster data with duckdb or similar:\n",
    "- https://www.linkedin.com/pulse/querying-stac-load-satellite-imagery-sentinel2-duckdb-alvaro-huarte-yjuzf/?trackingId=wfMPNnd%2BDh2zi1AoiLG2vg%3D%3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6b948-604b-4225-9134-909fdf88fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cubo \n",
    "import xarray as xr\n",
    "# }import rioxarray as rxr\n",
    "\n",
    "def percentile_normalize(da, lower_percentile=5, upper_percentile=95):\n",
    "    \"\"\"Normalize using percentiles to improve visualization contrast\"\"\"\n",
    "    # Calculate percentiles per band\n",
    "    mins = da.quantile(lower_percentile/100, dim=('x', 'y'))\n",
    "    maxs = da.quantile(upper_percentile/100, dim=('x', 'y'))\n",
    "    \n",
    "    # Apply normalization\n",
    "    normalized = (da - mins) / (maxs - mins)\n",
    "    return normalized.clip(0, 1)\n",
    "\n",
    "# use cubo to fetch a series of 4 tiles and visualize per their tutorial: https://cubo.readthedocs.io/en/latest/tutorials/getting_started.html\n",
    "def fetch_cubo_stac_rasters_samples(\n",
    "    pv_gdf: gpd.GeoDataFrame,\n",
    "    stac_url='https://planetarycomputer.microsoft.com/api/stac/v1',\n",
    "    collection='sentinel-2-l2a',\n",
    "    bands=['B02', 'B03', 'B04'],\n",
    "    start_date='2023-01-01',\n",
    "    end_date='2023-03-31',\n",
    "    units=\"m\",\n",
    "    edge_size=1280,\n",
    "    resolution=10,\n",
    "    sample_size=5,\n",
    "    visualize_set=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch raster samples from a STAC collection using Cubo and vi\n",
    "    Args:\n",
    "        pv_gdf (GeoDataFrame): Input GeoDataFrame with geometry column.\n",
    "        stac_url (str): STAC API URL.\n",
    "        collection (str): STAC collection name.\n",
    "        start_date (str): Start date for filtering.\n",
    "        end_date (str): End date for filtering.\n",
    "        units (str): Units for the raster data.\n",
    "        edge_size (int): Size of the edges of the raster tiles.\n",
    "        resolution (int): Resolution of the raster data.\n",
    "        sample_size (int): Number of samples to fetch.\n",
    "    Returns:\n",
    "        stac_xr_samples (xr.DataArray): Sampled raster data.\n",
    "\"\"\"\n",
    "\n",
    "    # Sort by area descending and sample\n",
    "    sampled_gdf = pv_gdf.sort_values(by='area_m2', ascending=False)\n",
    "    sampled_gdf = sampled_gdf[:1000].sample(sample_size, random_state=42)\n",
    "    # all should be using 'EPSG:4326'\n",
    "    target_epsg = sampled_gdf.crs\n",
    "    default_query = {\"eo:cloud_cover\": {\"lt\": 25}}\n",
    "    \n",
    "    stac_items = []\n",
    "    print(f\"Fetching samples for {len(sampled_gdf)} locations...\")\n",
    "    for idx, row in sampled_gdf.iterrows():\n",
    "        pv_lat, pv_long = row.geometry.centroid.y, row.geometry.centroid.x\n",
    "        print(f\"Fetching samples for {idx}: {pv_lat}, {pv_long} with area {row['area_m2']:.2f} m2\")\n",
    "        # Fetch samples using Cubo\n",
    "        try:\n",
    "            # Fetch samples using Cubo\n",
    "            # Pass the EPSG code as an integer, not a string with \"EPSG:\" prefix\n",
    "            pv_da = cubo.create(\n",
    "                lat=pv_lat,\n",
    "                lon=pv_long,\n",
    "                stac=stac_url,\n",
    "                collection=collection,\n",
    "                bands=bands,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                edge_size=1280,\n",
    "                units=units,\n",
    "                resolution=resolution,\n",
    "                # Use integer EPSG code instead of string with 'EPSG:' prefix\n",
    "                # stackstac_kw=dict( # stackstac keyword arguments\n",
    "                #     # xy_coords='center',\n",
    "                #     epsg=32611)\n",
    "                query=default_query\n",
    "            )\n",
    "\n",
    "            # return pv_da\n",
    "            \n",
    "            stac_items.append(pv_da)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching or visualizing data for {idx}: {e}\")\n",
    "    \n",
    "\n",
    "    if not stac_items:\n",
    "        print(\"No valid data items fetched.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    # visualize only last sample for now\n",
    "    if visualize_set and pv_da is not None:\n",
    "        # Check that the 'time' coordinate exists and has data\n",
    "        if \"time\" in pv_da.coords and len(pv_da.time) > 0:\n",
    "            # Calculate number of columns for the visualization grid\n",
    "            axes = min(4, len(pv_da.time))\n",
    "            # Display RGB composite by selecting red, green, blue bands and scaling\n",
    "            pv_da = pv_da.groupby('time').first()\n",
    "            rgb_da = percentile_normalize(pv_da.sel(band=[\"B04\", \"B03\", \"B02\"]))\n",
    "            rgb_da.plot.imshow(col=\"time\", col_wrap=axes)\n",
    "        \n",
    "        else:\n",
    "            print(f\"No data available for location {pv_lat}, {pv_long}\")\n",
    "    \n",
    "    try:\n",
    "        # First ensure all datasets have same dimensions and variables\n",
    "        aligned_items = []\n",
    "        for item in stac_items:\n",
    "            # Ensure all datasets use the same CRS\n",
    "            if item.rio.crs is None:\n",
    "                item = item.rio.write_crs(\"EPSG:4326\")\n",
    "            \n",
    "            # Add to aligned list\n",
    "            aligned_items.append(item)\n",
    "        \n",
    "        # Use rioxarray's merge functionality which handles spatial contexts better\n",
    "        # First combine by time (similar to your original approach)\n",
    "        merged_data = xr.concat(aligned_items, dim='time')\n",
    "        \n",
    "        # For spatial merging with overlapping tiles, you could use:\n",
    "        # merged_data = rxr.merge.merge_arrays(aligned_items)\n",
    "        \n",
    "        return merged_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error merging datasets: {e}\")\n",
    "        # If merge fails, return the list of items instead\n",
    "        print(\"Returning list of individual DataArrays without merging\")\n",
    "        return stac_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6c175-ebd4-4d69-be91-94f0473b1b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3680dec-50ab-4c4b-8526-12b49e1e736c",
   "metadata": {},
   "source": [
    "# Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec8f05-8dc0-466b-bbad-f2b8d32828bc",
   "metadata": {},
   "source": [
    "## Zarr and ARCO storage formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0113dc-8b04-4e88-9268-1cc60784367a",
   "metadata": {},
   "source": [
    "## Kerchunk and VirtualiZarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b5edd-f44b-4f80-9414-98b8934f7d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eo-pv-cv",
   "language": "python",
   "name": "eo-pv-cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
