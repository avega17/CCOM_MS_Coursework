\section{Background}

\begin{multicols}{2}

\subsubsection{Earth Observation and Remote Sensing}

Remote sensing (RS) refers to the process of acquiring images and data of the planet’s surface using a variety of remote sensors in satellite and aerial vehicles (add citations from my prev paper). 
These sensors analyze electromagnetic radiation reflected or emitted from objects on the Earth’s surface, which is then processed to extract information about the objects and their properties. 
Besides traditional electro-optical (ie panchromatic and 3-channel RGB images (cite)) modern RS employs a variety of sensors and modalities such as multispectral 
(four or more non-overlapping bands in the electromagnetic spectrum), hyperspectral (more than 100 narrow bands), and even active sensors such as microwave altimeters or Synthetic
Aperture Radar (SAR) that emit their own radiation and measure the reflected signal to ”see” at night and through atmospheric obstructions like clouds and fog (cite myself or refs from prev paper). 
Analysis of source data from these remote sensors must handle a variety of nuanced characteristics of each sensor and the produced data. For our purposes and the scope of this report, we will limit our discussion
to the following characteristics: 

\begin{itemize}
    \item Spatial resolution: The level of detail in an image, typically measured in meters per pixel.
    \item Spectral resolution: The ability of a sensor to distinguish between different wavelengths of light.
    \item Temporal resolution: The frequency at which a sensor captures data over the same location.
    \item Radiometric resolution: The sensitivity of a sensor to detect variations in intensity, often represented by bit depth.
    \item Earth Observation (EO) data types:
        \begin{enumerate}
            \item Raster data: Gridded data representing continuous surfaces.
            \item Vector data: Discrete data represented as points, lines, or polygons.
            \item Time series data: Sequential data capturing changes over time over a specific area.
            \item Geospatial data cubes: Multidimensional arrays combining spatial, temporal, and spectral dimensions.
        \end{enumerate}
\end{itemize}

% A fundamental challenge in RS is the tradeoff that an individual sensor's orbit and design must make between spatial, spectral, and temporal resolution. 


\subsubsection{Computer Vision}

Computer Vision (CV) is a subfield of Artificial Intelligence and a discipline that deals with the problem of interpreting and extracting meaningful information from images (cite myself or refs from prev paper) 
in a manner similar to human vision. This field has seen significant advancements in recent years, particularly with the rise of deep learning methods and the spread of large, labeled datasets for many applications. 
RS and EO has seen an explosion of interest, publications, and datasets for DL methods since 2015 (cite EO paper from cloud computing course). Relevant CV tasks for our purposes include:

\begin{enumerate}
    \item Scene Classification: Assigning a label to an entire image based on its content (e.g., classifying an image as containing a PV array, rooftop, or vegetation).
    \item Object Detection: Identifying and localizing specific object classes (e.g., PV panels) within an image with (georeferenced) bounding boxes.
    \item Semantic Segmentation: Classifying each pixel in an image into predefined categories (e.g., PV panel array, rooftop, vegetation, background).
    \item Instance Segmentation: Similar to semantic segmentation, but differentiates between \textit{individual} instances (e.g., distinguishing between different PV panel arrays). 
\end{enumerate}

Some relevant CV architectures include Convolutional Neural Networks (CNNs), Vision Transformers (ViTs), Generative Adversarial Networks (GANs), and CNN-Transformer hybrids. 

% - Importance of satellite imagery for monitoring renewable energy infrastructure.
% - Characteristics of PV arrays as seen from space (spectral, spatial).
% - Brief overview of relevant sensor types (multispectral, VHR).

\subsection{SpatioTemporal Asset Catalogs}
% * Role of STAC in standardizing access to geospatial raster data.
% * Structure of STAC (Catalogs, Collections, Items, Assets).
% * Challenges in efficiently querying large STAC archives for widespread, numerous PoIs.

\subsection{Discrete Global Grid Systems}
% * Introduction to DGGS concepts.
% * Specifics of H3: hexagonal, hierarchical, indexing capabilities (`h3.geo_to_h3`, `h3.k_ring`, `h3.grid_distance`).
% * Rationale for using H3 as the foundational grid for spatial aggregation and analysis (Li et al., 2024, for grid-based significance thinking; 
% Oje et al., 2025, for context on DGGS performance, even if HierGP is adaptive).

\subsection{Minimum Spanning Trees for Spatial and Hierarchical Clustering}
% * Concept of MSTs in graph theory.
% * Application of MSTs in clustering: identifying natural groupings by cutting edges.
% * Advantages for spatial data: ability to find clusters of arbitrary shapes (Gagolewski et al., 2023).





% \subsubsection{Data Fusion}

% \begin{enumerate}
%     \item Definition: combining data from multiple sources to achieve improved information quality or inference compared to using sources individually\cite{Castanedo_trad_data_fusion_2013} 
%     \item (Geospatial) Coherence\cite{Ghamisi_Multisource_and_Multitemporal_Data_Fusion_in_Remote_Sensing_2019}
%     \item Remote Sensing Fusion types\cite{Ghamisi_Multisource_and_Multitemporal_Data_Fusion_in_Remote_Sensing_2019}\cite{Li_DL_multimodal_RS_data_fusion_review_2022}
%     \begin{itemize}
%         \item Spatio-Spectral Fusion: Enhancing spectral resolution using spatial information (e.g., Pansharpening) or vice versa.\cite{Ghamisi_Multisource_and_Multitemporal_Data_Fusion_in_Remote_Sensing_2019}\cite{Zhang_panchromatic_and_msi_fusion_for_RS_and_EO_2023}
%         \item Spatio-Temporal Fusion: Combining high spatial resolution/low temporal frequency data with low spatial resolution/high temporal frequency data to generate a fused dataset with 
%         high resolution in both domains.\cite{Ghamisi_Multisource_and_Multitemporal_Data_Fusion_in_Remote_Sensing_2019} \textbf{This is the core fusion type for the second subproblem of this project}. 
%     \end{itemize}
%     \item Data Fusion Abstraction Levels\cite{Hussain_DL_Data_Fusion_review_2024}
%     \begin{itemize}
%         \item Early fusion (pixel/signal level): Combining raw sensor data directly 
%         \item Intermediate fusion (feature level): Extracting relevant features from each sensor first and then combining them
%         \item Late fusion (symbol/decision level): Each source produces an independent decision, which is then combined to produce a final output
%         % \item Hybrid fusion (combination of levels)
%     \end{itemize}
%     \item  A review from Castanedo\cite{Castanedo_trad_data_fusion_2013} also categorizes fusion based on the relationship between data sources (complementary, redundant, cooperative)
%     \item The rise of Deep Learning (DL) has significantly impacted the field, with reviews listing CNNs, LSTMs, GANs, and Transformers as the most relevant architectures for data fusion\cite{Li_DL_multimodal_RS_data_fusion_review_2022}\cite{Hussain_DL_Data_Fusion_review_2024}.
% \end{enumerate}

