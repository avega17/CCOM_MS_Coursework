{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1a316-0557-4f9b-a4a4-7b87337039c2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "import pprint as pp\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "from typing import Optional, List, Dict, Tuple, Any\n",
    "\n",
    "# Geospatial & Data Handling\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geodatasets # For geospatial datasets\n",
    "import duckdb\n",
    "import h3\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import xarray as xr # For ND-Array section\n",
    "import pystac_client # For STAC section\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from shapely import wkt\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pydeck as pdk\n",
    "import folium\n",
    "import lonboard\n",
    "\n",
    "# Presentation/Notebook Specific\n",
    "# from IPython.display import display, Markdown, Latex\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from jupyter_bbox_widget import BBoxWidget\n",
    "from ipywidgets import Layout, interact\n",
    "\n",
    "# data\n",
    "import duckdb\n",
    "import datahugger\n",
    "import sciencebasepy\n",
    "from seedir import seedir\n",
    "\n",
    "# Import refactored utility functions\n",
    "from utils.fetch_and_preprocess import (\n",
    "    fetch_dataset_files, \n",
    "    filter_gdf_duplicates, \n",
    "    process_vector_geoms, \n",
    "    geom_db_consolidate_dataset,\n",
    "    ddb_filter_duplicates\n",
    ")\n",
    "from utils.visualizations import (\n",
    "    format_dataset_info,\n",
    "    create_map_buttons,\n",
    "    create_folium_cluster_map,\n",
    "    create_folium_choropleth,\n",
    "    create_folium_heatmap,\n",
    "    create_pydeck_scatterplot,\n",
    "    create_pydeck_polygons,\n",
    "    create_pydeck_heatmap\n",
    ")\n",
    "\n",
    "from utils.st_context_processing import (\n",
    "    add_h3_index_to_pv_labels,\n",
    "    ddb_alter_table_add_h3,\n",
    "    ddb_save_div_matches,\n",
    "    ddb_save_subtype_geoms,\n",
    "    get_duckdb_connection,\n",
    "    group_pv_by_h3_cells,\n",
    "    spatial_join_stac_items_with_h3,\n",
    "    create_h3_stac_fetch_plan,\n",
    "    fetch_overture_maps_theme,\n",
    "    spatial_join_pv_overture_duckdb\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96706a2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Leveraging Hierarchical Spatial Clustering and DGGS for Planetary-scale surveys of Photovoltaic Solar Panel Arrays\n",
    "\n",
    "*CCOM6050: Analysis and Design of Algorithms*  \n",
    "**Alejandro Vega Nogales**  \n",
    "*Data Scientist @ Maxar Puerto Rico*   \n",
    "*CCOM MS Student*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc7bf3-344f-49e9-806f-8211b19017f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Outline\n",
    "\n",
    "1.  **Introduction & Background (Earth Observation)**\n",
    "    * Earth Observation (EO) \n",
    "    * Remote Sensing (RS)\n",
    "    * Geospatial Data\n",
    "    * Thesis Topic \n",
    "2.  **Data & Methodology**\n",
    "    * Open, Published PV Solar Panel Location Datasets\n",
    "    * Geospatial Data Handling \n",
    "        - Overture\n",
    "        - H3\n",
    "    * Cloud-Native Geospatial Stack\n",
    "        - GeoParquet \n",
    "        - DuckDB\n",
    "        - STAC Collections\n",
    "        - Xarray & ND-Arrays\n",
    "        - Virtualization & Virtual Datasets\n",
    "4.  **Algorithms Topic: Hierarchical Spatial Clustering**\n",
    "    * Relevant Algorithms & Literature\n",
    "        - Minimum Spanning Trees (1)\n",
    "        - DGGS (2)\n",
    "        - Unbounded Parallelism (3)\n",
    "    * Application with H3 for PV Cluster Analysis\n",
    "    * Minimizing STAC queries for multi-sensor and multi-temporal data\n",
    "5.  **Preliminary Findings & Next Steps**\n",
    "    * Preliminary Dataset description\n",
    "    * Testing Clustering with preliminary dataset and h3 (results in report)\n",
    "    * Testing STAC query performance improvements\n",
    "    * Scaling to the Cloud (Thesis)\n",
    "6.  **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c43c42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Earth Observation (EO): Fundamentals and Background\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f833698",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### What is Earth Observation (EO)?\n",
    "\n",
    "- Gathering information about Earth's physical, chemical, and biological systems via remote sensing technologies.\n",
    "- Sensors on satellites, aircraft, drones, etc.\n",
    "- Key characteristics: Spatial, Temporal, and Spectral Resolution.\n",
    "\n",
    "<figure style=\"text-align: right\">\n",
    "<img src=\"report/assets/figures/schmitt_et_al_fig1_geospatial_data.png\" style=\"width:auto; height:40%;\">\n",
    "<figcaption align = \"center\"> Illustration of different RS sources, imagery types, and imaging details </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305cd07-1d60-4d0f-a4c4-be68a045fd33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Sensor Modalities\n",
    "\n",
    "- **Optical:** Captures visible and near-infrared light (e.g., satellite imagery).\n",
    "  - Panchromatic (grayscale), True Color (RGB), Multispectral (4-15 bands), Hyperspectral (100+ bands).\n",
    "- **Radar (SAR):** Active sensor, penetrates clouds, measures surface properties and elevation.\n",
    "- **Thermal:** Detects heat emitted/reflected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad83652",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### EO Data Complexities\n",
    "\n",
    "- **Spatial Resolution (GSD):** Size of ground area covered by one pixel.\n",
    "- **Temporal Resolution:** Time between observations of the same location.\n",
    "- **Spectral Resolution:** Number and width of electromagnetic bands captured.\n",
    "- **Challenges:** Clouds, atmospheric distortion, data volume, coordinate systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8006c4a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Geospatial Data Types\n",
    "\n",
    "- **Raster:**\n",
    "  - Grid-based data (pixels).\n",
    "  - Represents continuous phenomena (e.g., elevation, temperature, imagery).\n",
    "  - Cell values store attribute information.\n",
    "- **Vector:**\n",
    "  - Coordinate-based data.\n",
    "  - Represents discrete features (e.g., points, lines, polygons).\n",
    "  - Examples: Roads (lines), buildings (polygons), PV panels (points/polygons)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd2744",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Proposed Thesis Topic: \n",
    "\n",
    "#### Leveraging _planetary-scale_ Datasets of PV Solar Panel locations to train Computer Vision models that enable Nation-scale PV Spatio-Temporal Surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c9de6d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Data & Methodology\n",
    "\n",
    "### Open, Published PV Solar Panel Locations\n",
    "\n",
    "- Aggregated multiple open, published datasets of PV locations worldwide.\n",
    "- Sources include Zenodo, Figshare, GitHub, ScienceBase.\n",
    "- Variety of formats (CSV, *GeoJSON* [ideal], Shapefile, etc.).\n",
    "- Goal: Create a consolidated, deduplicated dataset for analysis.\n",
    "\n",
    "Here we list the dataset titles of publications alongside their first author, DOI links, and their number of labels:\n",
    "- **\"Distributed solar photovoltaic array location and extent dataset for remote sensing object identification\"** - K. Bradbury, 2016 | [paper DOI](https://doi.org/10.1038/sdata.2016.106) | [dataset DOI](https://doi.org/10.6084/m9.figshare.3385780.v4) | polygon annotations for 19,433 PV modules in 4 cities in California, USA\n",
    "- \"A solar panel dataset of very high resolution satellite imagery to support the Sustainable Development Goals\" - C. Clark et al, 2023 | [paper DOI](https://doi.org/10.1038/s41597-023-02539-8) | [dataset DOI](https://doi.org/10.6084/m9.figshare.22081091.v3) | 2,542 object labels (per spatial resolution)\n",
    "- **\"A harmonised, high-coverage, open dataset of solar photovoltaic installations in the UK\" - D. Stowell et al, 2020** | [paper DOI](https://doi.org/10.1038/s41597-020-00739-0) | [dataset DOI](https://zenodo.org/records/4059881) | 265,418 data points (over 255,000 are stand-alone installations, 1067 solar farms, and rest are subcomponents within solar farms)\n",
    "- \"Georectified polygon database of ground-mounted large-scale solar photovoltaic sites in the United States\" - K. Sydny, 2023 | [paper DOI](https://doi.org/10.1038/s41597-023-02644-8) | [dataset DOI](https://www.sciencebase.gov/catalog/item/6671c479d34e84915adb7536) | 4186 data points \n",
    "- \"Vectorized solar photovoltaic installation dataset across China in 2015 and 2020\" - J. Liu et al, 2024 | [paper DOI](https://doi.org/10.1038/s41597-024-04356-z) | [dataset link](https://github.com/qingfengxitu/ChinaPV) | 3,356 PV labels (inspect quality!)\n",
    "- \"Multi-resolution dataset for photovoltaic panel segmentation from satellite and aerial imagery\" - H. Jiang, 2021 | [paper DOI](https://doi.org/10.5194/essd-13-5389-2021) | [dataset DOI](https://doi.org/10.5281/zenodo.5171712) | 3,716 samples of PV data points\n",
    "- \"A crowdsourced dataset of aerial images with annotated solar photovoltaic arrays and installation metadata\" - G. Kasmi, 2023 | [paper DOI](https://doi.org/10.1038/s41597-023-01951-4) | [dataset DOI](https://doi.org/10.5281/zenodo.6865878) | > 28K points of PV installations; 13K+ segmentation masks for PV arrays; metadata for 8K+ installations\n",
    "- **\"An Artificial Intelligence Dataset for Solar Energy Locations in India\"** - A. Ortiz, 2022 | [paper DOI](https://doi.org/10.1038/s41597-022-01499-9) | [dataset link 1](https://researchlabwuopendata.blob.core.windows.net/solar-farms/solar_farms_india_2021.geojson) or [dataset link 2](https://raw.githubusercontent.com/microsoft/solar-farms-mapping/refs/heads/main/data/solar_farms_india_2021_merged_simplified.geojson) | 117 geo-referenced points of solar installations across India\n",
    "- \"GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery\" - Z. Yang, 2024** | [paper DOI](https://doi.org/10.48550/arXiv.2404.05180) | [dataset DOI](https://github.com/yzyly1992/GloSoFarID/tree/main/data_coordinates) | 6,793 PV samples across 3 years (double counting of samples)\n",
    "- **\"A global inventory of photovoltaic solar energy generating units\" - L. Kruitwagen et al, 2021** | [paper DOI](https://doi.org/10.1038/s41586-021-03957-7) | [dataset DOI](https://doi.org/10.5281/zenodo.5005867) | 50,426 for training, cross-validation, and testing; 68,661 predicted polygon labels \n",
    "- **\"Harmonised global datasets of wind and solar farm locations and power\" - S. Dunnett et al, 2020** | [paper DOI](https://doi.org/10.1038/s41597-020-0469-8) | [dataset DOI](https://doi.org/10.6084/m9.figshare.11310269.v6) | 35272 PV installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8eb31-a4a8-4613-9482-9683b5d63f72",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "load_dotenv()\n",
    "DATASET_DIR = Path(os.getenv('DATA_PATH'))\n",
    "# read dataset metadata from json file\n",
    "with open('dataset_metadata.json', 'r') as f:\n",
    "    dataset_metadata = json.load(f)\n",
    "\n",
    "dataset_choices = [\n",
    "    'global_harmonized_large_solar_farms_2020',\n",
    "    'global_pv_inventory_sent2_2024',\n",
    "    'global_pv_inventory_sent2_spot_2021',\n",
    "    'fra_west_eur_pv_installations_2023',\n",
    "    'ind_pv_solar_farms_2022',\n",
    "    'usa_cali_usgs_pv_2016',\n",
    "    'chn_med_res_pv_2024',\n",
    "    'usa_eia_large_scale_pv_2023',\n",
    "    'uk_crowdsourced_pv_2020',\n",
    "    'deu_maxar_vhr_2023'   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581ef17-722e-44c3-ad42-7a88b8c19aa5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store selected datasets\n",
    "# mostly gen by github copilot with Claude 3.7 model\n",
    "selected_datasets = dataset_choices.copy()\n",
    "\n",
    "# Create an accordion to display selected datasets with centered layout\n",
    "dataset_accordion = widgets.Accordion(\n",
    "    children=[widgets.HTML(format_dataset_info(ds)) for ds in selected_datasets],\n",
    "    layout=Layout(width='50%', margin='0 auto')\n",
    ")\n",
    "for i, ds in enumerate(selected_datasets):\n",
    "    dataset_accordion.set_title(i, ds)\n",
    "\n",
    "# Define a function to add or remove datasets\n",
    "def manage_datasets(action, dataset=None):\n",
    "    global selected_datasets, dataset_accordion\n",
    "    \n",
    "    if action == 'add' and dataset and dataset not in selected_datasets:\n",
    "        selected_datasets.append(dataset)\n",
    "    elif action == 'remove' and dataset and dataset in selected_datasets:\n",
    "        selected_datasets.remove(dataset)\n",
    "    \n",
    "    # Update the accordion with current selections\n",
    "    dataset_accordion.children = [widgets.HTML(format_dataset_info(ds)) for ds in selected_datasets]\n",
    "    for i, ds in enumerate(selected_datasets):\n",
    "        dataset_accordion.set_title(i, ds)\n",
    "    \n",
    "    f\"Currently selected datasets: {len(selected_datasets)}\"\n",
    "\n",
    "# Create dropdown for available datasets\n",
    "dataset_dropdown = widgets.Dropdown(\n",
    "    options=list(dataset_metadata.keys()),\n",
    "    description='Dataset:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='70%', margin='20 20 auto 20 20')\n",
    ")\n",
    "\n",
    "# Create buttons for actions\n",
    "add_button = widgets.Button(description=\"Add Dataset\", button_style='success')\n",
    "remove_button = widgets.Button(description=\"Remove Dataset\", button_style='danger')\n",
    "\n",
    "# Define button click handlers\n",
    "def on_add_clicked(b):\n",
    "    manage_datasets('add', dataset_dropdown.value)\n",
    "\n",
    "def on_remove_clicked(b):\n",
    "    manage_datasets('remove', dataset_dropdown.value)\n",
    "\n",
    "# Link buttons to handlers\n",
    "add_button.on_click(on_add_clicked)\n",
    "remove_button.on_click(on_remove_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690227a7-d2ed-4624-a5a3-266c95fdba7a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Dataset Selection Interface\n",
    "#### Use the dropdown and buttons below to customize which solar panel datasets will be fetched and processed.\n",
    "- Select a dataset from the dropdown:\n",
    "    - Click \"Add Dataset\" to include it in processing\n",
    "    - Click \"Remove Dataset\" to exclude it\n",
    "- View metadata table for each selected dataset by clicking on it's row in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a2ea3-9498-430f-93e7-2a513019c8c6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the widgets\n",
    "display(widgets.HBox([dataset_dropdown, add_button, remove_button]))\n",
    "display(dataset_accordion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7e3a5",
   "metadata": {},
   "source": [
    "## Data Fusion: Geospatial Data Context and Handling\n",
    "\n",
    "- Focus on tools optimized for scalable cloud environments.\n",
    "- **Goal:** Process and analyze large geospatial datasets efficiently, leveraging cloud storage and compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c43a3",
   "metadata": {},
   "source": [
    "### Overture Maps: Adding Geospatial Context\n",
    "\n",
    "<!-- From their [Division theme guide](https://docs.overturemaps.org/guides/divisions/) and their [brief blog on the history of the project](https://overturemaps.org/blog/2025/overture-maps-foundation-making-open-data-the-winning-choice/): -->\n",
    "\n",
    "Overture Maps is a collaborative project that aims to create a high-quality, open map datasets for the entire world:\n",
    "    - The project is a collaboration between several organizations, including Meta, Amazon Web Services (AWS), and Microsoft. \n",
    "    - Overture distributes its open datasets as GeoParquet files, and can be accessed through CLI, API or downloaded directly from [their S3](https://docs.overturemaps.org/guides/divisions/#data-access-and-retrieval) buckets\n",
    "\n",
    "The Overture divisions theme: \n",
    "- has three feature types (division, **division_area**, and division_boundary) and contains more than 5.45 million point, line, and polygon representations of human settlements, such as countries, regions, states, cities, and even neighborhoods. \n",
    "- is derived from a conflation of OpenStreetMap data and geoBoundaries data\n",
    "- **Used here as contextual layers** (e.g. dividing our data by continent, country, etc) to enrich PV data.\n",
    "- their `division_area` subset provides a **hierarchical structure of administrative boundaries**, including countries, states, and cities.\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://docs.overturemaps.org/assets/images/divisions-admin0-admin1-coverage-ff1a8d4c6d68c88047b34d1f9c9109be.png\" style=\"width:65%; height:auto;\">\n",
    "<figcaption align = \"center\"> Overture divisions data, styled by subtype: countries in purple, region boundaries as green lines. </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269e70a",
   "metadata": {},
   "source": [
    "## Cloud-Native Geospatial Stack\n",
    "\n",
    "- Focus on tools optimized for scalable cloud environments.\n",
    "- **Goal:** Process and analyze large geospatial datasets efficiently, and can scale to leverage cloud storage and compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395762c",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### GeoParquet: Cloud-Optimized Vector Data\n",
    "<div style=\"max-width: 80%; margin: 0 auto; padding-left: 1em; padding-right: 1em; text-align: justify;\">\n",
    "<h4 style=\"text-align: left\">GeoParquet: Intro</h2>\n",
    "\n",
    "<p>GeoParquet is <a href=\"https://geoparquet.org/\">an incubating Open Geospatial Consortium (OGC) standard</a> that simply adds compatible geospatial <a href=\"https://docs.safe.com/fme/html/FME-Form-Documentation/FME-ReadersWriters/geoparquet/Geometry-Support.htm\">geometry types</a> (Point, Line, Polygon, etc) to the mature and widely adopted <a href=\"https://parquet.apache.org/\">Apache Parquet format</a>, a popular columnar storage file format commonly used in big data processing and modern data engineering pipelines and analytics. This is analogous to how the GeoTIFF raster format adds geospatial metadata to the longstanding TIFF standard. GeoParquet is designed to be a simple and efficient way to store geospatial <em>vector</em> data in a columnar format, and is designed to be compatible with existing Parquet tools and libraries to enable Cloud <em>Data Warehouse</em> Interoperability.</p>\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*QEQJjtnDb3JQ2xqhzARZZw.png\" style=\"width:70%; height:auto;\">\n",
    "<figcaption align = \"center\"> Visualization of the layout of a Parquet file </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3950ebdf",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"max-width: 80%; margin: 0 auto; padding-left: 1em; padding-right: 1em; text-align: justify;\">\n",
    "<h4 style=\"text-align: left\">GeoParquet: Internal Layout</h2>\n",
    "\n",
    "<p>These files are organized in a set of file chunks called \"row groups\". Row groups are logical groups of columns with the same number of rows. Each of these columns is actually a \"column chunk\" which is a contiguous block of data for that column. The schema across row groups must be consistent, i.e. the data types and number of columns must be the same for every row group. The new geospatial standard adds some relevant additional metadata such as the geometry's Coordinate Reference System (CRS), additional metadata for geometry columns, and <a href=\"https://medium.com/radiant-earth-insights/geoparquet-1-1-coming-soon-9b72c900fbf2\">support for spatial indexing in v1.1</a>.\n",
    "</div>\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://guide.cloudnativegeo.org/images/geoparquet_layout.png\" style=\"width:40%; height:auto;\">\n",
    "<figcaption align = \"center\"> GeoParquet has the same layout with additional metadata </figcaption>\n",
    "</figure>\n",
    "\n",
    "<!-- GeoParquet is only the latest in a long line of cloud-native file formats  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11710e4",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 77%; margin: 0 auto; padding-left: 1em; padding-right: 1em; text-align: justify;\">\n",
    "<h4 style=\"text-align: left\">GeoParquet: Features & Performance</h2>\n",
    "\n",
    "\n",
    "- Efficient storage and compression: \n",
    "    - Internally compressed by default, and can be configured to optimize decompression (time) or storage size (space)\n",
    "    - columnar format is more efficient for filtering on columns which is common in analytical workloads and results in better compression ratios vs row-based formats\n",
    "- Scalability and Efficient data access:\n",
    "    - Spatial indexing, spatial partitioning, and other optimizations enables\n",
    "        - spatial joins and containment operations like intersection, within, overlaps, etc (ST_*)\n",
    "        - [spatial predicate pushdowns](https://medium.com/radiant-earth-insights/geoparquet-1-1-coming-soon-9b72c900fbf2)\n",
    "            - can significantly speed up spatial queries over the network by **applying filters at the storage level**\n",
    "            - greatly reducing data movement if applied correctly\n",
    "- Optimized for *read-heavy workflows*: \n",
    "    - Parquet itself is an immutable file format, which means taking advantage of cheap reads, and efficient filtering and grouping\n",
    "    - Popular choice for storing large datasets using *modern cloud-centric DBMS architectures* like data lakes and data warehouses.\n",
    "    - Designed for analytical workloads that require fast reads and complex queries (but not transactions and frequent updates)\n",
    "        - idealfor OLAP (Online Analytical Processing) and BI (Business Intelligence) workloads\n",
    "        - these revolve around historical and aggregated data that dont require high-frequency updates\n",
    "- Cloud-native format: Optimized for object storage (s3, gcs, abfs, etc.)\n",
    "    - **designed to be highly compressed**, which reduces storage and data transfer costs and improves RW performance\n",
    "    - integrates into existing ecosystem of cloud data pipelines and workflows that have been built around the parquet format\n",
    "    - Broad and fast adoption across the data engineering and geospatial ecosystems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135acda5",
   "metadata": {},
   "source": [
    "- **Benefits for Spatial Analysis:**\n",
    "  - *Fast Joins & Aggregation:* Quickly combine data across datasets based on cell ID.\n",
    "  - *Efficient Neighborhood Queries:* Hexagons have uniform adjacency and H3 provides a built-in Grid Traversal API with distance metrics.\n",
    "  - *Hierarchical Structure:* Easy aggregation/disaggregation across resolutions (parent/child cells).\n",
    "  - *Optimized Grid Traversal:* Useful for spatial algorithms.\n",
    "  - **Foundation for spatial indexing and clustering in this work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb962ab5",
   "metadata": {},
   "source": [
    "### DuckDB: In-Process SQL OLAP RDBMS\n",
    "\n",
    "From their [\"Why DuckDB?\" page](https://duckdb.org/why_duckdb.html):\n",
    "\n",
    "DuckDB is an **in-process analytical data management system (OLAP RDBMS)**. Unlike traditional client-server databases (like PostgreSQL or MySQL), DuckDB runs directly within the host process (e.g., our Python script or Jupyter kernel), similar to SQLite. However, unlike SQLite which is optimized for transactional workloads (OLTP), DuckDB is specifically designed for **analytical queries (OLAP)** involving complex, long-running queries over potentially huge datasets, typical in big data analytics and scientific computing workflows.\n",
    "\n",
    "Key benefits for our workflow include:\n",
    "-   **Simplicity & Portability:** Easy installation (`pip install duckdb`) and no external dependencies or database server management required. Databases are stored as single, portable files (`.duckdb`), making them easy to manage, share, and archive.\n",
    "-   **Direct Data Access:** Can directly query various file formats, including the **Parquet and GeoParquet files** we are generating and (geo)pandas DataFrames(!), without needing a separate, time-consuming ingestion/copy step. This is highly efficient for consolidating data from multiple files, and remote sources (e.g., S3, GCS).\n",
    "-   **Powerful SQL:** Offers a rich, modern SQL dialect, including window functions, complex joins, and support for common table expressions (CTEs), allowing sophisticated data manipulation and analysis directly in SQL.\n",
    "-   **Geospatial Capabilities:** Crucially, DuckDB has a **`spatial` extension** that provides functions for handling and querying geospatial data types (like points, lines, and polygons) using libraries like GEOS. This enables operations such as spatial joins (e.g., `ST_Intersects`, `ST_Contains`), area calculations (`ST_Area`), centroid computation (`ST_Centroid`), and reading/writing WKT/WKB formats directly within the database. This is essential for our tasks like deduplication and integrating PV labels with contextual layers like Overture Maps.\n",
    "-   **Performance:** Its **column-vectorized query execution engine** is optimized for analytical performance, often *significantly faster than row-based systems* and more optimized than *pure Python/Pandas operations* for large datasets that may not fit into memory. \n",
    "-   **Python Integration:** Seamlessly integrates with Python libraries like Pandas and GeoPandas through its client API and tools like `jupysql`, allowing easy data exchange between dataframes and the database directly from our notebooks! \n",
    "\n",
    "We use DuckDB to:\n",
    "1.  Efficiently consolidate multiple GeoParquet files (one per source dataset) into a single database table using its ability to natively read Parquet (including directly from s3/httpfs!).\n",
    "2.  Leverage its `spatial` extension for geospatial indexing, filtering, and performing spatial joins with the [Overture Maps divisions](#Overture-Maps-Divisions) data based on [H3 indices](#H3-Geospatial-Indexing-System-and-Spatial-Clustering).\n",
    "3.  Provide a persistent, queryable, and portable database (`.duckdb` file) containing the cleaned, consolidated, and spatially enriched PV label data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47dc1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ZSTD_COMPRESSION = os.getenv(\"GPQ_ZSTD_COMPRESSION\", 5)\n",
    "TABLE_NAME = os.getenv(\"PV_DB_TABLE\", \"global_consolidated_pv\")\n",
    "\n",
    "dataset_choices = [\n",
    "    'global_harmonized_large_solar_farms_2020', 'global_pv_inventory_sent2_spot_2021', 'ind_pv_solar_farms_2022', 'usa_cali_usgs_pv_2016', 'uk_crowdsourced_pv_2020'\n",
    "]\n",
    "\n",
    "# get list of geoparquet files to be consolidated\n",
    "get_full_gpq_path = lambda f: DATASET_DIR / 'raw' / 'labels' / 'geoparquet' / f\n",
    "parquet_files = [get_full_gpq_path(f) for f in os.listdir(DATASET_DIR / 'raw' / 'labels' / 'geoparquet') if any(os.path.splitext(f)[0].startswith(ds) for ds in selected_datasets)]\n",
    "flist = '\\n-'.join([os.path.relpath(f) for f in parquet_files])\n",
    "print(f\"Consolidating these {len(parquet_files)} files:\\n-{flist}\")\n",
    "\n",
    "DB_DIR = Path(os.getenv(\"DUCKDB_DIR\", DATASET_DIR / 'db'))\n",
    "out_consolidated_parquet = DATASET_DIR / 'prepared' / 'labels' / 'geoparquet' / 'global_consolidated_pv.geoparquet'\n",
    "out_consolidated_db = DB_DIR / 'global_consolidated_pv.duckdb'\n",
    "# create the output directories if they don't exist\n",
    "print(f\"Creating output directories: {out_consolidated_parquet.parent}\")\n",
    "os.makedirs(out_consolidated_parquet.parent, exist_ok=True)\n",
    "\n",
    "# consolidate the dataset into a single duckdb database that will also be saved as a geoparquet file\n",
    "# exclude POINT and MULTIPOINT geometries until we have implemented a heuristic to extract a PV polygon label from the points\n",
    "# TODO: look at usability of SAM2 models that perform segmentation from single point input \n",
    "db_file = geom_db_consolidate_dataset(\n",
    "    parquet_files=parquet_files,\n",
    "    table_name=TABLE_NAME,\n",
    "    geom_column=\"geometry\",\n",
    "    keep_geoms=[\"POLYGON\", \"MULTIPOLYGON\", \"POINT\", \"MULTIPOINT\"],\n",
    "    spatial_index=True,\n",
    "    out_parquet=out_consolidated_parquet,\n",
    "    printout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd41bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "conn = get_duckdb_connection(db_file)\n",
    "%sql conn --alias duckdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bc2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display db tables\n",
    "%sql SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql DESCRIBE {{TABLE_NAME}};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b908747",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SUMMARIZE SELECT unified_id, area_m2, centroid_lon, centroid_lat, dataset, bbox FROM {{TABLE_NAME}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the consolidated geoparquet file into a geopandas for visualization\n",
    "%time ds_gdf = gpd.read_parquet(out_consolidated_parquet)\n",
    "print(f\"Loaded {len(ds_gdf)} geometries from {out_consolidated_parquet}\")\n",
    "# display some stats about our raw combined gdf\n",
    "print(f\"Combined {len(parquet_files)} datasets into one gdf with {len(ds_gdf)} rows and {len(ds_gdf.columns)} columns.\")\n",
    "print(f\"Combined gdf has the following columns:\\n{list(ds_gdf.columns)}\")\n",
    "display(ds_gdf.describe())\n",
    "display(ds_gdf.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source gdf for visualization directly from db in cases where ds_gdf is deleted further below\n",
    "fetch_query = f\"\"\"\n",
    "SELECT unified_id, dataset, area_m2, centroid_lon, centroid_lat, bbox, ST_AsText(geometry) AS geometry\n",
    "FROM {TABLE_NAME}; \"\"\"\n",
    "%time viz_gdf = conn.sql(fetch_query).df()\n",
    "\n",
    "# convert the geometry column from WKT to shapely geometries\n",
    "viz_gdf = gpd.GeoDataFrame(viz_gdf, geometry=viz_gdf['geometry'].apply(wkt.loads), crs=\"EPSG:4326\")\n",
    "# only keep the rows that have area_m2 > 0\n",
    "viz_gdf = viz_gdf[viz_gdf['area_m2'] > 0]\n",
    "# # sample 100K rows for visualization\n",
    "# viz_gdf = viz_gdf.sample(50000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693094ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql DESCRIBE country_geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SUMMARIZE SELECT country_iso, division_name, country_pv_count, country_pv_area_m2 FROM country_geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d35328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get country geoms in gdf \n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "countries_query = f\"\"\"\n",
    "SELECT division_id, country_iso, division_name, country_pv_count, country_pv_area_m2, ST_AsText(geometry) AS geometry\n",
    "FROM country_geoms;\"\"\"\n",
    "country_gdf = conn.sql(countries_query).df()\n",
    "# convert the geometry column from WKT to shapely geometries\n",
    "country_gdf = gpd.GeoDataFrame(country_gdf, geometry=country_gdf['geometry'].apply(wkt.loads), crs=\"EPSG:4326\")\n",
    "\n",
    "# plot chloropleth map of the country geoms colored by the number of PV installations\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"left\", size=\"5%\", pad=0.1)\n",
    "\n",
    "country_gdf.plot(column='country_pv_count', ax=ax,\n",
    "    cmap='viridis', linewidth=0.8,  edgecolor='0.8',\n",
    "   legend=True, cax=cax, vmin=0, vmax=country_gdf['country_pv_count'].max(),\n",
    "    legend_kwds={'label': \"Number of PV Installations\",\n",
    "                 'orientation': \"vertical\", 'shrink': 0.5, 'aspect': 30,\n",
    "                 'ticks': [0, 1000, 2000, 3000, 4000, 5000]})\n",
    "ax.set_title('Number of PV Installations by Country', fontdict={'fontsize': '25', 'fontweight' : '3'})\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ad710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare interactive scatterplot map with Folium\n",
    "\n",
    "# first plot geodatasets natural earth basemap\n",
    "natural_earth = geodatasets.get_path('naturalearth.land')\n",
    "natural_earth_gdf = gpd.read_file(natural_earth)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "natural_earth_gdf.plot(ax=ax, color='lightgray', edgecolor='black')\n",
    "# plot the country geometries \n",
    "# country_gdf.plot(ax=ax, color='none', edgecolor='black', linewidth=0.5)\n",
    "# plot the PV installations\n",
    "viz_gdf.plot(ax=ax, color='red', markersize=5, alpha=0.8)\n",
    "plt.title(f'PV Installation Scatterplot (n={len(viz_gdf)})', fontsize=20)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94a7cd",
   "metadata": {},
   "source": [
    "### Querying and Searching STAC Collections\n",
    "\n",
    "- **S**patio**T**emporal **A**sset **C**atalog (STAC).\n",
    "- Standardized specification for describing geospatial information.\n",
    "- Enables searching and discovery of EO data (imagery, etc.) across different catalog providers (e.g. Microsoft Planetary Computer, AWS Open Data, Google Earth Engine, etc.)\n",
    "- STAC collections are a standardized way to describe datasets, including metadata, spatial and temporal extents, and links to assets.\n",
    "- Key concepts: \n",
    "    - **STAC Item**: Represents a single observation or asset, including metadata and links to assets (e.g., images, metadata files).\n",
    "    - **STAC Collection**: A collection of STAC items and collections, organized hierarchically.\n",
    "    - **STAC Catalog**: A collection of STAC items and collections, organized hierarchically.\n",
    "    - **STAC API**: RESTful API for searching and retrieving STAC items and collections.\n",
    "    - **STAC Browser**: Web-based interface for exploring and visualizing STAC collections.\n",
    "- Libraries like `pystac-client` facilitate programmatic searching based on spatial (bbox, geometry) and temporal criteria.\n",
    "    - STAC API supports CQL (Common Query Language) for complex queries over catalog fields (e.g. `datetime` in range, `eo:cloud_coverage` < 20%, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap\n",
    "m = leafmap.Map(center=[36.844461, 37.386475], zoom=8)\n",
    "url = 'https://github.com/opengeos/maxar-open-data/raw/master/datasets/Kahramanmaras-turkey-earthquake-23.geojson'\n",
    "m.add_geojson(url, layer_name=\"Footprints\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('report/assets/figures/maxar_stac_demo_tile_footprints.gif', width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab7207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"https://radiantearth.github.io/stac-browser/#/external/maxar-opendata.s3.amazonaws.com/events/catalog.json?.language=en\", width=1080, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e3a1c",
   "metadata": {},
   "source": [
    "### Xarray and ND-arrays in Scientific Computing\n",
    "\n",
    "- Xarray introduces labels (dimensions, coordinates, attributes) to multi-dimensional arrays (like NumPy's ndarray).\n",
    "- **Benefits for Geospatial/EO Data:**\n",
    "  - Handles complex data like satellite image time series (e.g., dimensions: time, band, y, x).\n",
    "  - Facilitates operations like alignment, indexing, and aggregation based on labels (e.g., time series analysis, **operations over multispectral bands**).\n",
    "  - Integrates well with Dask for **parallel computing on large datasets**\n",
    "- Common in climate science, oceanography, and remote sensing that require analysis of multi-dimensional data.\n",
    "- **Xarray + Dask:** Enables parallel processing of large datasets, leveraging Dask's task scheduling and lazy evaluation.\n",
    "- **Xarray + GeoParquet:** Enables efficient reading/writing of geospatial data in Parquet format, leveraging Xarray's capabilities for handling multi-dimensional data.\n",
    "- **Xarray + STAC:** Enables easy access to EO data stored in STAC collections, allowing for efficient querying and analysis of large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74049d8e",
   "metadata": {},
   "source": [
    "### The Critical Role of Virtualization in Cloud Advances\n",
    "\n",
    "- **Foundation of Cloud Computing:** Allows abstraction of physical hardware (networks, storage, compute, you name it!) into virtual, ephemeral resources.\n",
    "- **Resource Pooling & Elasticity:** Enables efficient sharing and dynamic allocation/scaling of compute, storage, and network resources centralized in data centers distributed across the globe.\n",
    "- **Separation of Concerns:** Decouples applications from **underlying infrastructure**, allowing developers to focus on building applications without worrying about hardware management and reproducibility across environments.\n",
    "- **Cost Efficiency:** Pay-as-you-go model for resources, reducing upfront costs and allowing for on-demand scaling.\n",
    "    - **Cost Efficiency:** Pay-as-you-go model reduces upfront capital expenses.\n",
    "        - Cloud providers offer flexible pricing models (on-demand, reserved, spot instances).\n",
    "        - Be aware of potential vendor lock-in and hidden costs that can impact long-term economics.\n",
    "    - **Computational Scale:** Access to dirt-cheap storage and massive computing resources on demand without infrastructure management overhead.\n",
    "        - **Making Big Data Cheap:** Easily scale resources up or down, enabling rapid deployment and cost-effective huge analytical workloads.\n",
    "- **Enabler for:**\n",
    "  - Infrastructure as a Service (IaaS), Platform as a Service (PaaS), Software as a Service (SaaS).\n",
    "  - Modern data architectures (Data Lakes, Lakehouses)\n",
    "  - **Serverless computing**\n",
    "    - particularly relevant for data processing and analysis\n",
    "    - easier to scale and manage briefly as needed for analysis\n",
    "        - e.g. no need to keep a high-availability cluster with replicas and failover running 24/7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976f48c",
   "metadata": {},
   "source": [
    "### Rise of Virtual Datasets in EO \n",
    "\n",
    "(Kerchunk, VirtuliZarr, Icechunk)\n",
    "\n",
    "- **Concept:** Datasets defined by *references* to data assets stored elsewhere (often cloud object storage), rather than containing the data itself.\n",
    "    - Pointers or references, but for TB's of scientific data.\n",
    "    - These formats create lightweight indexes that map to specific byte ranges in cloud-stored files.\n",
    "- **Motivation:** Avoid data duplication and large data transfers; analyze data *in place*, facilitate rapid development of derivative data products from huge raw data.\n",
    "- **Benefits:** \n",
    "        - Avoids data duplication and large data transfers.\n",
    "        - Enables analysis of data *in place*.\n",
    "        - Facilitates sharing and collaboration without transferring large datasets.\n",
    "- **Impact:** Enables efficient analysis of massive planetary-scale archives (e.g., climate models, satellite imagery) directly from cloud storage.\n",
    "- **Examples:**\n",
    "  - **Kerchunk:** Creates reference files that map logical chunks (e.g., in Xarray) to byte ranges in cloud storage. Allowing libraries like Xarray to read cloud data **as if it were a single local file**\n",
    "      - completely serverless architecture: asynchronous concurrent fetching, parallel access to multiple files, and lazy loading of data\n",
    "      - supports reading from all of the storage backends supported by fsspec (s3, gcs, abfs, etc), http, cloud user storage (dropbox, **gdrive**) and network protocols (ftp, ssh, hdfs, smb…)\n",
    "      - default JSON schema can be slow to load and heavy on memory → **supports exporting references as [parquet files](https://fsspec.github.io/kerchunk/spec.html#parquet-references)** for efficient storage and retrieval\n",
    "  - **VirtualiZarr:** Similar concepts for creating virtual Zarr datasets via Kerchunk references.\n",
    "  - **Icechunk:** A rising file format based on Apache Iceberg for chunked data access in cloud storage, enabling efficient reading of large datasets without downloading them entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb55917",
   "metadata": {},
   "source": [
    "## Hierarchical Spatial Clustering: \n",
    "\n",
    "- **Hierarchical Clustering:** Groups data points into a hierarchy of clusters.\n",
    "- **Spatial Clustering:** Groups data points based on their spatial proximity.\n",
    "- **Hierarchical Spatial Clustering:** Combines both concepts, creating a hierarchy of clusters based on spatial relationships.\n",
    "- **Benefits:**\n",
    "  - Captures multi-scale spatial patterns.\n",
    "  - Provides a hierarchical structure for data exploration and analysis.\n",
    "  - Useful for large datasets with varying spatial resolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee5696",
   "metadata": {},
   "source": [
    "### \"Clustering with minimum spanning trees: How good can it be?\"\n",
    "\n",
    "- **What:** A Graph with set of nodes V and edges E. *Connects all vertices in a weighted, undirected graph with minimum total edge weight*, no cycles\n",
    "    * Key property: n vertices ⟹n−1 edges.\n",
    "- **Why?:**: \n",
    "    * Natural cluster representation: Removing k−1 \"longest\"  MST edges yields k clusters (connected components)\n",
    "    * Detects clusters of arbitrary shapes (see fig) unlike k-means and other methods that require knowing number of cluster a priori\n",
    "    * Foundation for various clustering algorithms (single linkage, divisive, agglomerative).\n",
    "- **Answer:** \n",
    "    * Authors: \n",
    "        - \"As far as the current benchmark battery is concerned, the MST-based methods outperform the popular “parametric” approaches (Gaussian Mixtures, K-means) and other algorithms (Birch, Ward, Average, Complete linkage, and spectral clustering with proper parameters) implemented in the scikit-learn package\"\n",
    "        - \"[MST Clustering methods] are quite simple and easy to compute: once the minimum spanning tree is considered (which takes up to O(n2) time, but approximate methods exist as well) we can potentially **get a whole hierarchy of clusters of any cardinality**\"\n",
    "            - \"For instance, our top performer...needs O(n√n) to *generate all possible partitions given a prebuilt MST*\"\n",
    "\n",
    "<!-- display MST cluster examples -->\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"report/assets/figures/mst_arbitrary_clusters.png\" style=\"width:40%; height:40%;\">\n",
    "<figcaption align = \"center\"> MST to Cluster examples </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87835c0",
   "metadata": {},
   "source": [
    "### Discrete Global Grid Systems and Geospatial Indexing\n",
    "\n",
    "<!-- From their [home page](https://h3geo.org/), [announcement blog](https://www.uber.com/blog/h3/), and [overview page](https://h3geo.org/docs/core-library/overview/): -->\n",
    "- **What:** A Consistent global framework for Hierarchical *tessellation* of Earth's surface into cells. \n",
    "- **H3 DGGS:**\n",
    "    * The H3 geospatial indexing system is a **discrete global grid system** developed at Uber (2018)\n",
    "    * It was designed for indexing geographies via multi-resolution tiling into a **hexagonal grid with hierarchical indexes**.\n",
    "        - Advantages of Hexagons: Uniform neighbor distances, good for spatial calculations\n",
    "    * Geospatial coords can be indexed to *cell IDs* at diff. resolutions (0-15) that each represent a *unique cell* in the grid at each resolution.\n",
    "    * Natural clustering of PoIs/RoIs within H3's hierarchy\n",
    "        - The hexagonal grid system is designed to be **hierarchical**, meaning that each cell at a given resolution can be subdivided into 7 smaller cells at higher resolutions, allowing for efficient spatial queries and analysis.\n",
    "\n",
    "   \n",
    "<!-- It is common to use WGS84/EPSG:4326 CRS data with the H3 library. -->\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=100,onerror=redirect,format=auto/wp-content/uploads/2018/06/Twitter-H3.png\" style=\"width:75%; height:50%;\">\n",
    "<figcaption align = \"center\"> H3 enables users to partition the globe into hexagons for more accurate analysis. </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2073c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "# display h3 viewer \n",
    "IFrame(\"https://h3.chotard.com\", width=1080, height=540)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5795b",
   "metadata": {},
   "source": [
    "## Application in \"Planning for Earth Imaging Tasks via Grid Significance Mapping\"\n",
    "\n",
    "- proposes using H3 to uniformly map Points of Interest (PoIs) and Regions of Interest (RoIs) for EO satellite **future** task planning\n",
    "- H3 levels (e.g., 6 and 7) are chosen so grid cell sizes are relevant to **satellite strip widths** for better planning\n",
    "- introduces a method to calculate the \"significance\" or importance of each grid cell based on the POI's it contains\n",
    "- these and other authors note how clustering your data in grids lends itself easily for parallelization \n",
    "- **Let's flip the time dimension!:**\n",
    "    *  Instead of planning **new** image acquisitions, this grid significance scheme can be used to **optimize queries to STAC** archives for **existing imagery**\n",
    "    * **Objective:** *Maximize coverage* of your clustered dataset while *minimizing the number of queries* and downloaded STAC assets.\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"report/assets/figures/h3_dggs_EO_tasks.png\" style=\"width:70%; height:60%;\">\n",
    "<figcaption align = \"center\"> H3 DGGS for EO tasks </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c61f44a",
   "metadata": {},
   "source": [
    "### Research References\n",
    "- \"Fast Parallel Algorithms for Euclidean Minimum Spanning Tree and Hierarchical Spatial Clustering∗\"\n",
    "- \"Optimal Parallel Algorithms for Dendrogram Computation and Single-Linkage Clustering\" (resolves and parallelizes sequential bottleneck in algorithm above)\n",
    "- \"PANDORA: A Parallel Dendrogram Construction Algorithm for Single Linkage Clustering on GPU\" (same as above but for GPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77006acb",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Application with H3 for PV Cluster Analysis\n",
    "\n",
    "- **Goal:** Identify optimal spatial clusters of PV solar panel labels.\n",
    "- **Approach:**\n",
    "  - Use Uber's H3 DGGS.\n",
    "  - Index PV label locations (centroids or polygons) into H3 cells at an appropriate resolution.\n",
    "  - Treat H3 cells containing PV labels as the nodes/vertices in the clustering algorithms.\n",
    "- **Leveraging H3 Features:**\n",
    "  - **Proximity:** Efficiently find neighboring cells (`k_ring`).\n",
    "  - **Hierarchy:** Quickly compute parent/child cells for potential multi-resolution clustering or aggregation.\n",
    "  - **Traversal:** Efficient grid traversal algorithms can be adapted.\n",
    "- **Hypothesis:** H3 provides a performant spatial indexing foundation for implementing and scaling these hierarchical clustering algorithms, especially for distributed/parallel computation (relevant to thesis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795ca3f-8072-4164-a971-2f8b2241e1bb",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Application to PV Array Analysis: Next steps & Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e82ba",
   "metadata": {},
   "source": [
    "# [Live Demo]: \n",
    "\n",
    "## Rogar al profe para que permita entregar el reporte escrito más tarde esta semana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d1b3d",
   "metadata": {},
   "source": [
    "# ¡Gracias! ¿Preguntas?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eo-pv-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
