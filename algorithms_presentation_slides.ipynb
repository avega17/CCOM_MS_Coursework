{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e7bc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "f39e7bc6",
    "outputId": "2bcd6fd3-9e73-4c46-d9bf-12ccb4a7bed0",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import os\n",
    "    import random\n",
    "    import shutil\n",
    "    print('Running on CoLab')\n",
    "    from google.colab import drive\n",
    "    from google.colab import userdata\n",
    "    import secrets\n",
    "\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    # create dirs to mirror local file tree\n",
    "    os.makedirs('/content/datasets/raw/labels', exist_ok=True)\n",
    "    os.makedirs('/content/datasets/raw/images', exist_ok=True)\n",
    "\n",
    "    # copy over report folder for figures and other assets, and utils scripts\n",
    "    os.makedirs('/content/report', exist_ok=True)\n",
    "    # copy over metadata *.json files\n",
    "    if not os.path.exists('/dataset_metadata.json') or not os.path.exists('/content/dataset_metadata.json'):\n",
    "        shutil.copy('/content/drive/MyDrive/CCOM_MS_Training_Datasets_Logs/dataset_metadata.json', '/')\n",
    "        shutil.copy('/content/drive/MyDrive/CCOM_MS_Training_Datasets_Logs/dataset_metadata.json', '/content/')\n",
    "    if not os.path.exists('/spatio-temporal_metadata.json'):\n",
    "        shutil.copy('/content/drive/MyDrive/CCOM_MS_Training_Datasets_Logs/spatio-temporal_metadata.json', '/')\n",
    "    # copy over duckdb databases\n",
    "    if not os.path.exists('/content/datasets/db'):\n",
    "        shutil.copytree('/content/drive/MyDrive/CCOM_MS_Training_Datasets_Logs/datasets/db', '/content/datasets/db')\n",
    "        print(\"Copied over duckdb\")\n",
    "    # copy over raw geoparquet datasets\n",
    "    if not os.path.exists('/content/datasets/raw/labels/geoparquet'):\n",
    "        shutil.copytree('/content/drive/MyDrive/CCOM_MS_Training_Datasets_Logs/datasets/raw/labels/geoparquet', '/content/datasets/raw/labels/geoparquet')\n",
    "        print(\"Copied over geoparquet labels\")\n",
    "    if not os.path.exists('/content/report/assets'):\n",
    "        shutil.copytree('/content/drive/MyDrive/CCOM_MS_Training_Datasets_Logs/report/assets', '/content/report/assets')\n",
    "    if not os.path.exists('/content/utils'):\n",
    "        shutil.copytree('/content/drive/MyDrive/CCOM_MS_Training_Datasets_Logs/utils', '/content/utils')\n",
    "    if not os.path.exists('./.env'):\n",
    "        shutil.copy('/content/drive/MyDrive/CCOM_MS_Training_Datasets_Logs/.env', './.env')\n",
    "\n",
    "    !ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369f9b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "2369f9b3",
    "outputId": "2f7ce839-6a1f-4580-de90-137e3f3931df",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    colab_train_requirements = [\n",
    "        'geopandas'\n",
    "        , 'geodatasets'\n",
    "        , 'mapclassify'\n",
    "        , 'duckdb'\n",
    "        , 'duckdb-engine'\n",
    "        , 'jupysql'\n",
    "        , 'seedir' # package for creating, editing, and reading folder tree diagrams; not used here but imported in utils\n",
    "        , 'datahugger' # same as above\n",
    "        , 'dotenv'\n",
    "        , 'shapely'\n",
    "        , 'folium',\n",
    "        'pydeck'\n",
    "        ,'h3'\n",
    "    ]\n",
    "\n",
    "    !pip install --quiet {' '.join(colab_train_requirements)}\n",
    "\n",
    "    # install rapids zero-code gpu accelration libraries: https://rapids.ai/learn-more/#accelerators\n",
    "    !pip install --extra-index-url=https://pypi.nvidia.com \"cudf-cu12==25.4.*\" \"cuml-cu12==25.4.*\" \"cuvs-cu12==25.4.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1a316-0557-4f9b-a4a4-7b87337039c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "5cf1a316-0557-4f9b-a4a4-7b87337039c2",
    "outputId": "f921c4c2-60e6-48d2-a557-b8123c39c5b1",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "import pprint as pp\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "from typing import Optional, List, Dict, Tuple, Any\n",
    "\n",
    "# Geospatial & Data Handling\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geodatasets # For geospatial datasets\n",
    "import duckdb\n",
    "import h3\n",
    "# import xarray as xr # For ND-Array section\n",
    "# import pystac_client # For STAC section\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from shapely import wkt\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "\n",
    "# Presentation/Notebook Specific\n",
    "# from IPython.display import display, Markdown, Latex\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, interact\n",
    "\n",
    "# data\n",
    "import duckdb\n",
    "\n",
    "# Import refactored utility functions\n",
    "from utils.fetch_and_preprocess import (\n",
    "    fetch_dataset_files,\n",
    "    filter_gdf_duplicates,\n",
    "    process_vector_geoms,\n",
    "    geom_db_consolidate_dataset,\n",
    "    ddb_filter_duplicates\n",
    ")\n",
    "from utils.visualizations import (\n",
    "    format_dataset_info,\n",
    "    create_folium_cluster_map,\n",
    "    create_folium_choropleth,\n",
    "    create_pydeck_scatterplot,\n",
    "    create_pydeck_heatmap\n",
    ")\n",
    "\n",
    "from utils.st_context_processing import (\n",
    "    add_h3_index_to_pv_labels,\n",
    "    ddb_alter_table_add_h3,\n",
    "    ddb_save_div_matches,\n",
    "    ddb_save_subtype_geoms,\n",
    "    get_duckdb_connection,\n",
    "    group_pv_by_h3_cells,\n",
    "    spatial_join_stac_items_with_h3,\n",
    "    create_h3_stac_fetch_plan,\n",
    "    fetch_overture_maps_theme,\n",
    "    spatial_join_pv_overture_duckdb\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96706a2e",
   "metadata": {
    "editable": true,
    "id": "96706a2e",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Leveraging Hierarchical Spatial Clustering for Optimized Fetching of Planetary-scale Earth-Observation Datasets of Photovoltaic Solar Panel Array Locations\n",
    "\n",
    "*CCOM6050: Analysis and Design of Algorithms*  \n",
    "**Alejandro Vega Nogales**  \n",
    "*Data Scientist <strike>Apprentice</strike> @ Maxar Puerto Rico*   \n",
    "*CCOM MS Student*  \n",
    "May 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc7bf3-344f-49e9-806f-8211b19017f9",
   "metadata": {
    "editable": true,
    "id": "2ccc7bf3-344f-49e9-806f-8211b19017f9",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Outline\n",
    "\n",
    "1.  **Earth Observation (EO):** Introduction & Background\n",
    "2.  **Data & Methodology**\n",
    "    * Open, Published PV Solar Panel Location Datasets\n",
    "    * Geospatial Data Handling\n",
    "    * Cloud-Optimized Geospatial Stack\n",
    "4.  **Algorithms Topic: Hierarchical Spatial Clustering**\n",
    "    * Relevant Algorithms & Literature\n",
    "    * Application for PV installation Cluster Analysis\n",
    "    * Optimizing queries for Spatio-temporal Archives of EO Data\n",
    "5.  **Preliminary Findings & Next Steps**\n",
    "6.  **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c43c42",
   "metadata": {
    "editable": true,
    "id": "47c43c42",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Earth Observation: Introduction and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f833698",
   "metadata": {
    "editable": true,
    "id": "7f833698",
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### What is Earth Observation (EO)?\n",
    "\n",
    "<div style=\"display: flex; flex-direction: row; align-items: flex-start;\">\n",
    "    <div style=\"flex: 1; padding-right: 20px;\">\n",
    "        <ul>\n",
    "            <li>Gathering information about Earth's physical, chemical, and biological systems via remote sensing technologies.</li>\n",
    "            <li>Sensors on satellites, aircraft, drones, etc.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"flex: 2;\">\n",
    "        <figure style=\"text-align: right; margin: 0;\">\n",
    "            <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/schmitt_et_al_fig1_geospatial_data.png?raw=1\" style=\"width:60%;\">\n",
    "            <figcaption align=\"right\" style=\"font-size: 0.8em;\">Illustration of different RS sources, imagery types, and imaging details</figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305cd07-1d60-4d0f-a4c4-be68a045fd33",
   "metadata": {
    "editable": true,
    "id": "d305cd07-1d60-4d0f-a4c4-be68a045fd33",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Sensor Modalities\n",
    "\n",
    "<div style=\"display: flex; flex-direction: row; align-items: flex-start;\">\n",
    "    <div style=\"flex: 2; padding-right: 20px;\">\n",
    "        <ul>\n",
    "            <li> Different sensors capture different types of data.</li>\n",
    "            <li> Each sensor has its own characteristics and applications.</li>\n",
    "            <li> <strong>Optical</strong>: Captures visible and near-infrared light (e.g., satellite imagery). </li>\n",
    "            <li> <strong>Panchromatic</strong> (grayscale) </li>\n",
    "            <li> <strong>True Color</strong> (RGB) </li>\n",
    "            <li> <strong>Multispectral</strong> (4-15 bands)\n",
    "            <li> <strong>Hyperspectral</strong> (100+ bands). </li>\n",
    "            <li> <strong>Radar (SAR)</strong>: Active sensor, penetrates clouds, measures surface properties and elevation.</li>\n",
    "            <li> <strong>Thermal</strong>: Detects heat emitted/reflected.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"flex: 1;\">\n",
    "        <figure style=\"text-align: center;\">\n",
    "        <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/remote_sensing_data_examples.png?raw=1\" style=\"width:100%;\">\n",
    "        <figcaption align=\"center\" style=\"font-size: 0.8em;\">EO Sensor modalities example</figcaption>\n",
    "    </figure>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad83652",
   "metadata": {
    "editable": true,
    "id": "8ad83652",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### EO Data Complexities\n",
    "\n",
    "<div style=\"display: flex; flex-direction: row; align-items: flex-start;\">\n",
    "    <div style=\"flex: 1; padding-right: 20px;\">\n",
    "        <ul>\n",
    "            <li><strong>Spatial Resolution (GSD):</strong> Size of ground area covered by one pixel.</li>\n",
    "            <li><strong>Temporal Resolution:</strong> Time between observations of the same location.</li>\n",
    "            <li><strong>Spectral Resolution:</strong> Number and width of electromagnetic bands captured.</li>\n",
    "            <li><strong>Challenges:</strong> Clouds, atmospheric distortion, data volume, variety of coordinate systems.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"flex: 1; display: flex; flex-direction: column;\">\n",
    "        <figure style=\"text-align: center; margin-bottom: 20px;\">\n",
    "            <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/Different-kinds-of-resolution-with-examples-of-lower-and-higher-resolution-data-Spatial.png?raw=1\" style=\"width:100%;\">\n",
    "            <figcaption align=\"center\" style=\"font-size: 0.8em;\">EO Data complexities</figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8006c4a1",
   "metadata": {
    "editable": true,
    "id": "8006c4a1",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Geospatial Data Types\n",
    "\n",
    "- **Raster:**\n",
    "  - Grid-based data (pixels).\n",
    "  - Represents continuous phenomena (e.g., elevation, temperature, imagery).\n",
    "  - Cell values store attribute information.\n",
    "      \n",
    "- **Vector:**\n",
    "  - Coordinate-based data.\n",
    "  - Represents discrete features (e.g., points, lines, polygons).\n",
    "  - Examples: Roads (lines), buildings (polygons), PV panels (points/polygons).\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/jiayang_fig2_gbd_survey_rs_data_types.png?raw=1\" style=\"width:50%;\">\n",
    "<figcaption align=\"center\" style=\"font-size: 0.8em;\">Geospatial Data Types</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd2744",
   "metadata": {
    "editable": true,
    "id": "6ccd2744",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Proposed Thesis Topic:\n",
    "\n",
    "# Leveraging _Global_ **Datasets** of PV Solar Panel locations to train Computer Vision models that enable Nation-scale Spatio-Temporal **Surveys of Installed Solar Capacity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c9de6d",
   "metadata": {
    "editable": true,
    "id": "03c9de6d",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Data & Methodology\n",
    "\n",
    "### Open, Published PV Solar Panel Locations\n",
    "\n",
    "- Aggregated multiple open, published datasets of **PV locations worldwide**\n",
    "- Sources include Zenodo, Figshare, GitHub, ScienceBase.\n",
    "- Variety of formats (CSV, *GeoJSON* [ideal], Shapefile, etc.).\n",
    "- **Goal: Create a consolidated, deduplicated dataset for analysis.**\n",
    "\n",
    "Here we list the dataset titles of publications alongside their first author, DOI links, and their number of labels:\n",
    "- **\"Distributed solar photovoltaic array location and extent dataset for remote sensing object identification\"** - K. Bradbury, 2016 | [paper DOI](https://doi.org/10.1038/sdata.2016.106) | [dataset DOI](https://doi.org/10.6084/m9.figshare.3385780.v4) | polygon annotations for 19,433 PV modules in 4 cities in California, USA\n",
    "- \"A solar panel dataset of very high resolution satellite imagery to support the Sustainable Development Goals\" - C. Clark et al, 2023 | [paper DOI](https://doi.org/10.1038/s41597-023-02539-8) | [dataset DOI](https://doi.org/10.6084/m9.figshare.22081091.v3) | 2,542 object labels (per spatial resolution)\n",
    "- **\"A harmonised, high-coverage, open dataset of solar photovoltaic installations in the UK\" - D. Stowell et al, 2020** | [paper DOI](https://doi.org/10.1038/s41597-020-00739-0) | [dataset DOI](https://zenodo.org/records/4059881) | 265,418 data points (over 255,000 are stand-alone installations, 1067 solar farms, and rest are subcomponents within solar farms)\n",
    "- \"Georectified polygon database of ground-mounted large-scale solar photovoltaic sites in the United States\" - K. Sydny, 2023 | [paper DOI](https://doi.org/10.1038/s41597-023-02644-8) | [dataset DOI](https://www.sciencebase.gov/catalog/item/6671c479d34e84915adb7536) | 4186 data points\n",
    "- \"Vectorized solar photovoltaic installation dataset across China in 2015 and 2020\" - J. Liu et al, 2024 | [paper DOI](https://doi.org/10.1038/s41597-024-04356-z) | [dataset link](https://github.com/qingfengxitu/ChinaPV) | 3,356 PV labels (inspect quality!)\n",
    "- \"Multi-resolution dataset for photovoltaic panel segmentation from satellite and aerial imagery\" - H. Jiang, 2021 | [paper DOI](https://doi.org/10.5194/essd-13-5389-2021) | [dataset DOI](https://doi.org/10.5281/zenodo.5171712) | 3,716 samples of PV data points\n",
    "- \"A crowdsourced dataset of aerial images with annotated solar photovoltaic arrays and installation metadata\" - G. Kasmi, 2023 | [paper DOI](https://doi.org/10.1038/s41597-023-01951-4) | [dataset DOI](https://doi.org/10.5281/zenodo.6865878) | > 28K points of PV installations; 13K+ segmentation masks for PV arrays; metadata for 8K+ installations\n",
    "- **\"An Artificial Intelligence Dataset for Solar Energy Locations in India\"** - A. Ortiz, 2022 | [paper DOI](https://doi.org/10.1038/s41597-022-01499-9) | [dataset link 1](https://researchlabwuopendata.blob.core.windows.net/solar-farms/solar_farms_india_2021.geojson) or [dataset link 2](https://raw.githubusercontent.com/microsoft/solar-farms-mapping/refs/heads/main/data/solar_farms_india_2021_merged_simplified.geojson) | 117 geo-referenced points of solar installations across India\n",
    "- \"GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery\" - Z. Yang, 2024** | [paper DOI](https://doi.org/10.48550/arXiv.2404.05180) | [dataset DOI](https://github.com/yzyly1992/GloSoFarID/tree/main/data_coordinates) | 6,793 PV samples across 3 years (double counting of samples)\n",
    "- **\"A global inventory of photovoltaic solar energy generating units\" - L. Kruitwagen et al, 2021** | [paper DOI](https://doi.org/10.1038/s41586-021-03957-7) | [dataset DOI](https://doi.org/10.5281/zenodo.5005867) | 50,426 for training, cross-validation, and testing; 68,661 predicted polygon labels\n",
    "- **\"Harmonised global datasets of wind and solar farm locations and power\" - S. Dunnett et al, 2020** | [paper DOI](https://doi.org/10.1038/s41597-020-0469-8) | [dataset DOI](https://doi.org/10.6084/m9.figshare.11310269.v6) | 35272 PV installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8eb31-a4a8-4613-9482-9683b5d63f72",
   "metadata": {
    "editable": true,
    "id": "e9c8eb31-a4a8-4613-9482-9683b5d63f72",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "load_dotenv()\n",
    "DATASET_DIR = Path(os.getenv('DATA_PATH'))\n",
    "# read dataset metadata from json file\n",
    "with open('dataset_metadata.json', 'r') as f:\n",
    "    dataset_metadata = json.load(f)\n",
    "\n",
    "dataset_choices = [\n",
    "    'global_harmonized_large_solar_farms_2020',\n",
    "    'global_pv_inventory_sent2_2024',\n",
    "    'global_pv_inventory_sent2_spot_2021',\n",
    "    'fra_west_eur_pv_installations_2023',\n",
    "    'ind_pv_solar_farms_2022',\n",
    "    'usa_cali_usgs_pv_2016',\n",
    "    'chn_med_res_pv_2024',\n",
    "    'usa_eia_large_scale_pv_2023',\n",
    "    'uk_crowdsourced_pv_2020',\n",
    "    'deu_maxar_vhr_2023'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581ef17-722e-44c3-ad42-7a88b8c19aa5",
   "metadata": {
    "editable": true,
    "id": "1581ef17-722e-44c3-ad42-7a88b8c19aa5",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store selected datasets\n",
    "# mostly gen by github copilot with Claude 3.7 model\n",
    "selected_datasets = dataset_choices.copy()\n",
    "\n",
    "# Create an accordion to display selected datasets with centered layout\n",
    "dataset_accordion = widgets.Accordion(\n",
    "    children=[widgets.HTML(format_dataset_info(ds)) for ds in selected_datasets],\n",
    "    layout=Layout(width='50%', margin='0 auto')\n",
    ")\n",
    "for i, ds in enumerate(selected_datasets):\n",
    "    dataset_accordion.set_title(i, ds)\n",
    "\n",
    "# Define a function to add or remove datasets\n",
    "def manage_datasets(action, dataset=None):\n",
    "    global selected_datasets, dataset_accordion\n",
    "\n",
    "    if action == 'add' and dataset and dataset not in selected_datasets:\n",
    "        selected_datasets.append(dataset)\n",
    "    elif action == 'remove' and dataset and dataset in selected_datasets:\n",
    "        selected_datasets.remove(dataset)\n",
    "\n",
    "    # Update the accordion with current selections\n",
    "    dataset_accordion.children = [widgets.HTML(format_dataset_info(ds)) for ds in selected_datasets]\n",
    "    for i, ds in enumerate(selected_datasets):\n",
    "        dataset_accordion.set_title(i, ds)\n",
    "\n",
    "    f\"Currently selected datasets: {len(selected_datasets)}\"\n",
    "\n",
    "# Create dropdown for available datasets\n",
    "dataset_dropdown = widgets.Dropdown(\n",
    "    options=list(dataset_metadata.keys()),\n",
    "    description='Dataset:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='70%', margin='20 20 auto 20 20')\n",
    ")\n",
    "\n",
    "# Create buttons for actions\n",
    "add_button = widgets.Button(description=\"Add Dataset\", button_style='success')\n",
    "remove_button = widgets.Button(description=\"Remove Dataset\", button_style='danger')\n",
    "\n",
    "# Define button click handlers\n",
    "def on_add_clicked(b):\n",
    "    manage_datasets('add', dataset_dropdown.value)\n",
    "\n",
    "def on_remove_clicked(b):\n",
    "    manage_datasets('remove', dataset_dropdown.value)\n",
    "\n",
    "# Link buttons to handlers\n",
    "add_button.on_click(on_add_clicked)\n",
    "remove_button.on_click(on_remove_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690227a7-d2ed-4624-a5a3-266c95fdba7a",
   "metadata": {
    "editable": true,
    "id": "690227a7-d2ed-4624-a5a3-266c95fdba7a",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Dataset Selection Interface\n",
    "#### Use the dropdown and buttons below to customize which solar panel datasets will be fetched and processed.\n",
    "- Select a dataset from the dropdown:\n",
    "    - Click \"Add Dataset\" to include it in processing\n",
    "    - Click \"Remove Dataset\" to exclude it\n",
    "- View metadata table for each selected dataset by clicking on it's row in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a2ea3-9498-430f-93e7-2a513019c8c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871,
     "referenced_widgets": [
      "bd0f159e0be646bba7b5e0f52a9c0f1d",
      "4a7eb2ea85f84e7c9f6b37ea7aefcf64",
      "09a2b7ee32754e7eb9fe34a770854724",
      "10c2da4ed16942da9fdb465774e0ee1d",
      "9d1cd0eb102c46db8e2d15d6f1ed3f32",
      "e97bf40ef0d644a3b78c1d5105229300",
      "631aed21feb54400b23effeb8964bd50",
      "701b093ffef841a9bc0af94b216dad00",
      "3b1e419e614f41a59b1e714684cfcca9",
      "ee43018fc8ff48f9950f43d12603e6bf",
      "e6bed87f1d174dfaa4d73e2011530c0c",
      "20a4adcfbce94822a298120ae70d893c",
      "b73d075c675b4f2f87c2052a4467f82f",
      "12903e2f609349a59a7969b42647331b",
      "d3ce0dbf4f924d0faa83dc2570343d93",
      "0212797887204f0cbf7b9e43ce7c7a37",
      "e0b58531977d4430a47a328e88fd2b1a",
      "52c81b689723446599cc618be827cd77",
      "79f91a0d9cfc45bba6296a1e46836958",
      "71a0d6243b634fd181d9c3396bf2ea63",
      "2a134b5b515740e490315fba2a2f82ec",
      "7e6404486698452b896c8f72de6d36b4",
      "0c2ae1d3b63a4ce7893787099b7630ae",
      "36281434de954595bfa7b8f06f2989ec",
      "fe50001aa0ee4396a5f6dbfbc259e5ca",
      "a665a9de2b47453ca9b6813304a43435",
      "e5e7df6aab5549538688979689769b3e",
      "da28753e1bee474e9a9b7e0f7251828b",
      "cfd8b4fcd56049b3ae7de4b1ab494023",
      "39c5eb12abaf45b8bd14893d5e6f80d7",
      "cf2172aeac9c4e58a60800531a280b6a",
      "b2e77a6ef3cf43f7ad9308f06a131b9f",
      "7810554680ee4bf1a125e2f2e52b8e18",
      "716ca56235384ff384e5f2c60af6637b",
      "4d3783db57a041ca86f7018f4c93811d",
      "0ebc521f428c4847a6183580f897f19c",
      "a7c619d853354fd2ae3a46edfccd12c9",
      "dc17c5bead354a5a92b67a615c146ce5",
      "605bcd8f92bc44218d23d99b6124b5ee",
      "532f434545f543fd83d3f7e8694a0916",
      "51774ac77a6d4e72823a286cd6a7e69d",
      "8d7f81d461044dcb91e283ed1e3fec5c",
      "5372b84c820f4c53ae412968b58b115e",
      "998f103570f5455c950926baa6432a08",
      "9fb9bdd1f4fb44d5bfb7614ffd565f4c"
     ]
    },
    "editable": true,
    "id": "9c4a2ea3-9498-430f-93e7-2a513019c8c6",
    "outputId": "1b51015d-4ef2-4006-f5c9-512fed28c1b4",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the widgets\n",
    "out = widgets.Output()\n",
    "with out:\n",
    "    display(widgets.HBox([dataset_dropdown, add_button, remove_button]))\n",
    "    display(dataset_accordion)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7e3a5",
   "metadata": {
    "editable": true,
    "id": "b4d7e3a5",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Data Fusion: Geospatial Data Context and Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c43a3",
   "metadata": {
    "editable": true,
    "id": "d67c43a3",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Overture Maps: Adding Geospatial Context\n",
    "\n",
    "<!-- From their [Division theme guide](https://docs.overturemaps.org/guides/divisions/) and their [brief blog on the history of the project](https://overturemaps.org/blog/2025/overture-maps-foundation-making-open-data-the-winning-choice/): -->\n",
    "\n",
    "Overture Maps is a collaborative project that aims to create a high-quality, open map datasets for the entire world:\n",
    "    - The project is a collaboration between several organizations, including Meta, Amazon Web Services (AWS), and Microsoft.\n",
    "    - Overture distributes its open datasets as GeoParquet files, and can be accessed through CLI, API or downloaded directly from [their S3](https://docs.overturemaps.org/guides/divisions/#data-access-and-retrieval) buckets\n",
    "\n",
    "The Overture divisions theme:\n",
    "- has three feature types (division, **division_area**, and division_boundary) and contains more than 5.45 million point, line, and polygon representations of human settlements, such as countries, regions, states, cities, and even neighborhoods.\n",
    "- is derived from a conflation of OpenStreetMap data and geoBoundaries data\n",
    "- **Used here as contextual layers** (e.g. dividing our data by continent, country, etc) to enrich PV data.\n",
    "- their `division_area` subset provides a **hierarchical structure of administrative boundaries**, including countries, states, and cities.\n",
    "\n",
    "Overture publishes several Geospatial themes including Global Buildings, Land Cover, etc. that will be explored in future work.\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://docs.overturemaps.org/assets/images/divisions-admin0-admin1-coverage-ff1a8d4c6d68c88047b34d1f9c9109be.png\" style=\"width:65%; height:auto;\">\n",
    "<figcaption align = \"center\"> Overture divisions data, styled by subtype: countries in purple, region boundaries as green lines. </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269e70a",
   "metadata": {
    "editable": true,
    "id": "9269e70a",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Cloud-Optimized Geospatial Stack\n",
    "\n",
    "- Focus on tools optimized for scalable cloud environments.\n",
    "- **Goal:** Process and analyze large geospatial datasets efficiently, and can scale to leverage cloud storage and compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395762c",
   "metadata": {
    "editable": true,
    "id": "0395762c",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### GeoParquet: Cloud-Optimized Vector Data\n",
    "<div style=\"max-width: 80%; margin: 0 auto; padding-left: 1em; padding-right: 1em; text-align: justify;\">\n",
    "<h4 style=\"text-align: left\">GeoParquet: Intro</h4>\n",
    "\n",
    "<p>GeoParquet is <a href=\"https://geoparquet.org/\">an incubating Open Geospatial Consortium (OGC) standard</a> that simply adds compatible geospatial <a href=\"https://docs.safe.com/fme/html/FME-Form-Documentation/FME-ReadersWriters/geoparquet/Geometry-Support.htm\">geometry types</a> (Point, Line, Polygon, etc) to the mature and widely adopted <a href=\"https://parquet.apache.org/\">Apache Parquet format</a>, a popular columnar storage file format commonly used in big data processing and modern data engineering pipelines and analytics. This is analogous to how the GeoTIFF raster format adds geospatial metadata to the longstanding TIFF standard. GeoParquet is designed to be a simple and efficient way to store geospatial <em>vector</em> data in a columnar format, and is designed to be compatible with existing Parquet tools and libraries to enable Cloud <em>Data Warehouse</em> Interoperability.</p>\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*QEQJjtnDb3JQ2xqhzARZZw.png\" style=\"width:70%; height:auto;\">\n",
    "<figcaption align = \"center\"> Visualization of the layout of a Parquet file </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3950ebdf",
   "metadata": {
    "editable": true,
    "id": "3950ebdf",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div style=\"max-width: 85%; margin: 0 auto; padding-left: 1em; padding-right: 1em; text-align: justify;\">\n",
    "<h4 style=\"text-align: left\">GeoParquet: Internal Layout</h4>\n",
    "\n",
    "<p>These files are organized in a set of file chunks called \"row groups\".  \n",
    "Row groups are logical groups of columns with the same number of rows.  \n",
    "Each of these columns is actually a \"column chunk\" which is a contiguous block of data for that column.  \n",
    "The schema across row groups must be consistent, i.e. the data types and number of columns must be the same for every row group.  \n",
    "The new geospatial standard adds some relevant additional metadata such as the geometry's Coordinate Reference System (CRS),  \n",
    "additional metadata for geometry columns, and <a href=\"https://medium.com/radiant-earth-insights/geoparquet-1-1-coming-soon-9b72c900fbf2\">\n",
    "support for spatial indexing in v1.1</a>. </p>\n",
    "</div>\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://guide.cloudnativegeo.org/images/geoparquet_layout.png\" style=\"width:40%; height:auto;\">\n",
    "<figcaption align = \"center\"> GeoParquet has the same layout with additional metadata </figcaption>\n",
    "</figure>\n",
    "\n",
    "<!-- GeoParquet is only the latest in a long line of cloud-native file formats  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11710e4",
   "metadata": {
    "editable": true,
    "id": "b11710e4",
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<h4 style=\"text-align: left\">GeoParquet: Features & Performance</h4>\n",
    "\n",
    "\n",
    "- Efficient storage and compression:\n",
    "    - Internally compressed by default, and can be configured to optimize decompression (time) or storage size (space)\n",
    "    - Columnar format is more efficient for filtering on columns which is common in analytical workloads and results in better compression ratios vs row-based formats\n",
    "- Scalability and Efficient data access:\n",
    "    - Spatial indexing, spatial partitioning, and other optimizations enables\n",
    "        - spatial joins and containment operations like intersection, within, overlaps, etc (ST_*)\n",
    "        - [spatial predicate pushdowns](https://medium.com/radiant-earth-insights/geoparquet-1-1-coming-soon-9b72c900fbf2) can significantly speed up spatial queries over the network by **applying filters at the storage level**\n",
    "- Optimized for *read-heavy workflows*:\n",
    "    - Parquet itself is an immutable file format, which means taking advantage of cheap reads, and efficient filtering and grouping\n",
    "    - Popular choice for storing large datasets using *modern cloud-centric DBMS architectures* like data lakes and data warehouses.\n",
    "    - Designed for analytical workloads that require fast reads and complex queries (but not transactions and frequent updates)\n",
    "        - ideal for OLAP (Online Analytical Processing) and BI (Business Intelligence) workloads\n",
    "        - these revolve around historical and aggregated data that dont require high-frequency updates\n",
    "- Cloud-native format: Optimized for object storage (s3, gcs, abfs, etc.)\n",
    "    - **Designed to be highly compressed**, which reduces storage and data transfer costs and improves RW performance\n",
    "    - Integrates into existing ecosystem of cloud data pipelines and workflows that have been built around the parquet format\n",
    "    - Broad and fast adoption across the data engineering and geospatial ecosystems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb962ab5",
   "metadata": {
    "editable": true,
    "id": "eb962ab5",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### DuckDB: In-Process SQL OLAP RDBMS\n",
    "\n",
    "From their [\"Why DuckDB?\" page](https://duckdb.org/why_duckdb.html):\n",
    "\n",
    "DuckDB is an **in-process analytical data management system (OLAP RDBMS)**. Unlike traditional client-server databases (like PostgreSQL or MySQL), DuckDB runs directly within the host process (e.g., our Python script or Jupyter kernel), similar to SQLite. However, unlike SQLite which is optimized for transactional workloads (OLTP), DuckDB is specifically designed for **analytical queries (OLAP)** involving complex, long-running queries over potentially huge datasets, typical in big data analytics and scientific computing workflows.\n",
    "\n",
    "Key benefits for our workflow include:\n",
    "-   **Simplicity & Portability:** Easy installation (`pip install duckdb`) and no external dependencies or database server management required. Databases are stored as single, portable files (`.duckdb`), making them easy to manage, share, and archive.\n",
    "-   **Direct Data Access:** Can directly query various file formats, including the **Parquet and GeoParquet files** we are generating and (geo)pandas DataFrames(!), without needing a separate, time-consuming ingestion/copy step. This is highly efficient for consolidating data from multiple files, and remote sources (e.g., S3, GCS).\n",
    "-   **Powerful SQL:** Offers a rich, modern SQL dialect, including window functions, complex joins, and support for common table expressions (CTEs), allowing sophisticated data manipulation and analysis directly in SQL.\n",
    "-   **Geospatial Capabilities:** Crucially, DuckDB has a **`spatial` extension** that provides functions for handling and querying geospatial data types (like points, lines, and polygons) using libraries like GEOS. This enables operations such as spatial joins (e.g., `ST_Intersects`, `ST_Contains`), area calculations (`ST_Area`), centroid computation (`ST_Centroid`), and reading/writing WKT/WKB formats directly within the database. This is essential for our tasks like deduplication and integrating PV labels with contextual layers like Overture Maps.\n",
    "-   **Performance:** Its **column-vectorized query execution engine** is optimized for analytical performance, often *significantly faster than row-based systems* and more optimized than *pure Python/Pandas operations* for large datasets that may not fit into memory.\n",
    "-   **Python Integration:** Seamlessly integrates with Python libraries like Pandas and GeoPandas through its client API and tools like `jupysql`, allowing easy data exchange between dataframes and the database directly from our notebooks!\n",
    "\n",
    "We use DuckDB to:\n",
    "1.  Efficiently **consolidate multiple GeoParquet files into a single database table** using its ability to *natively read Parquet* (including directly from s3/httpfs!).\n",
    "2.  Leverage its `spatial` extension for **geospatial indexing, filtering, and performing spatial joins** with the Overture Maps divisions data based on H3 indices.\n",
    "3.  Provide a **persistent, queryable, and portable database** (`.duckdb` file) containing the cleaned, consolidated, and spatially enriched PV label data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47dc1aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465,
     "referenced_widgets": [
      "cac93cec3dc34e679c1e9cb445bc4123",
      "de662957079d4c8ea5061d4436f6f066",
      "ddc7b019dcc84a5789f4eb4862baff01"
     ]
    },
    "editable": true,
    "id": "b47dc1aa",
    "outputId": "40984f28-f07e-4534-e59c-b0a2810d4720",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "TABLE_NAME = os.getenv(\"PV_DB_TABLE\", \"global_consolidated_pv\")\n",
    "selected_datasets = [\n",
    "    'global_harmonized_large_solar_farms_2020', 'global_pv_inventory_sent2_spot_2021', 'ind_pv_solar_farms_2022', 'usa_cali_usgs_pv_2016', 'uk_crowdsourced_pv_2020'\n",
    "]\n",
    "\n",
    "# get list of geoparquet files to be consolidated\n",
    "get_full_gpq_path = lambda f: DATASET_DIR / 'raw' / 'labels' / 'geoparquet' / f\n",
    "parquet_files = [get_full_gpq_path(f) for f in os.listdir(DATASET_DIR / 'raw' / 'labels' / 'geoparquet') if any(os.path.splitext(f)[0].startswith(ds) for ds in selected_datasets)]\n",
    "flist = '\\n-'.join([os.path.relpath(f) for f in parquet_files])\n",
    "print(f\"Consolidating these {len(parquet_files)} files:\\n-{flist}\")\n",
    "\n",
    "DB_DIR = Path(os.getenv(\"DUCKDB_DIR\", DATASET_DIR / 'db'))\n",
    "out_consolidated_parquet = DATASET_DIR / 'prepared' / 'labels' / 'geoparquet' / 'global_consolidated_pv.geoparquet'\n",
    "out_consolidated_db = DB_DIR / 'global_consolidated_pv.duckdb'\n",
    "# create the output directories if they don't exist\n",
    "print(f\"Creating output directories: {out_consolidated_parquet.parent}\")\n",
    "os.makedirs(out_consolidated_parquet.parent, exist_ok=True)\n",
    "\n",
    "# consolidate the dataset into a single duckdb database that will also be saved as a geoparquet file\n",
    "db_file = geom_db_consolidate_dataset(\n",
    "    parquet_files=parquet_files,\n",
    "    table_name=TABLE_NAME,\n",
    "    geom_column=\"geometry\",\n",
    "    keep_geoms=[\"POLYGON\", \"MULTIPOLYGON\", \"POINT\", \"MULTIPOINT\"],\n",
    "    spatial_index=True,\n",
    "    out_parquet=out_consolidated_parquet,\n",
    "    printout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd41bc8",
   "metadata": {
    "editable": true,
    "id": "dbd41bc8",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "conn = get_duckdb_connection(db_file)\n",
    "%sql conn --alias duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bc2de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "editable": true,
    "id": "356bc2de",
    "outputId": "7e7ff0a4-5aa0-4e9f-f3aa-dc27fc010b28",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display db tables\n",
    "%sql SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df737e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "editable": true,
    "id": "e0df737e",
    "outputId": "a36e6421-96f6-4c26-a8d2-a5cdcc6cfae7",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql DESCRIBE {{TABLE_NAME}};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b908747",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "editable": true,
    "id": "2b908747",
    "outputId": "9524db9d-e830-4a4b-a31e-0d637b09c903",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql SUMMARIZE SELECT unified_id, area_m2, centroid_lon, centroid_lat, dataset, bbox FROM {{TABLE_NAME}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9da73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "editable": true,
    "id": "27a9da73",
    "outputId": "27c9f3ca-cb7c-456f-fa47-62b3c6c2babd",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the consolidated geoparquet file into a geopandas for visualization\n",
    "%time ds_gdf = gpd.read_parquet(out_consolidated_parquet)\n",
    "print(f\"Loaded {len(ds_gdf)} geometries from {out_consolidated_parquet}\")\n",
    "# display some stats about our raw combined gdf\n",
    "print(f\"Combined {len(parquet_files)} datasets into one gdf with {len(ds_gdf)} rows and {len(ds_gdf.columns)} columns.\")\n",
    "print(f\"Combined gdf has the following columns:\\n{list(ds_gdf.columns)}\")\n",
    "display(ds_gdf.describe())\n",
    "display(ds_gdf.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd1dfb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "b6fd1dfb",
    "outputId": "fdee507e-1245-427b-8ee3-47a241bd7ab4",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source gdf for visualization directly from db in cases where ds_gdf is deleted further below\n",
    "fetch_query = f\"\"\"\n",
    "SELECT unified_id, dataset, area_m2, centroid_lon, centroid_lat, bbox, ST_AsText(geometry) AS geometry\n",
    "FROM {TABLE_NAME}; \"\"\"\n",
    "%time viz_gdf = conn.sql(fetch_query).df()\n",
    "\n",
    "# convert the geometry column from WKT to shapely geometries\n",
    "viz_gdf = gpd.GeoDataFrame(viz_gdf, geometry=viz_gdf['geometry'].apply(wkt.loads), crs=\"EPSG:4326\")\n",
    "# only keep the rows that have area_m2 > 0\n",
    "viz_gdf = viz_gdf[viz_gdf['area_m2'] > 0]\n",
    "# # sample 100K rows for visualization\n",
    "# viz_gdf = viz_gdf.sample(50000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6FabuLzF-NJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "d6FabuLzF-NJ",
    "outputId": "e15693fb-9b32-46ec-e138-d2b0625acc49",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "\n",
    "    with open(\"/spatio-temporal_metadata.json\", \"r\") as file:\n",
    "        st_metadata = json.load(file)\n",
    "\n",
    "    OVERTURE_DIVISION_AREA_S3 = st_metadata[\"overture_divisions_area\"][\"s3_path\"]\n",
    "    OVERTURE_LAND_COVER_S3 = st_metadata[\"overture_base_land_cover\"][\"s3_path\"]\n",
    "\n",
    "    ov_divisions_table = os.getenv(\"DIVISIONS_DB_TABLE\", \"overture_division_areas\")\n",
    "    # only fetch these division types as more granular divisions are not needed for our analysis\n",
    "    division_types = [\n",
    "        'dependency',\n",
    "        'country',\n",
    "        'region',\n",
    "        'county'\n",
    "    ]\n",
    "    div_filters = {\"subtype\": (\"IN\", division_types)}\n",
    "\n",
    "    print(f\"Fetching Overture divisions from {OVERTURE_DIVISION_AREA_S3} into DuckDB database {out_consolidated_db} …\")\n",
    "    fetch_success = fetch_overture_maps_theme(\n",
    "        s3_path=OVERTURE_DIVISION_AREA_S3,\n",
    "        db_file=str(out_consolidated_db),\n",
    "        table_name=ov_divisions_table,\n",
    "        filter_dict=div_filters,\n",
    "        out_gpq_path=None  # no need to export to geoparquet here\n",
    "    )\n",
    "    if fetch_success:\n",
    "        print(\"Overture divisions fetched and stored in DuckDB successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to fetch Overture divisions into DuckDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LYBzlU0RHYbN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185,
     "referenced_widgets": [
      "1e96b418b6b048278d336f2ca124ac1d",
      "b3d6747010154a259e3e195d08b8a900",
      "0ac3e43c11204d0d9e6eaa8fc726bb32",
      "5963b4e350e7434fa6ef4faa30cea23d",
      "4259614a95df415fb76da4530b3e848c",
      "1fd1acb050b14072b3623796c1721958"
     ]
    },
    "editable": true,
    "id": "LYBzlU0RHYbN",
    "outputId": "f51a579c-4004-462b-853c-78a479f2ef9c",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "\n",
    "\n",
    "    # add a common h3 index at the same resolution to both our pv labels and overture divisions for easier spatial joins\n",
    "    common_h3_res = 5 # ~250km^2; roughly corresponds to many sensors swath widths, and San Juan, PR is ~200km^2\n",
    "    # common_h3_res = 4 # ~1770km^2; children cells can be used for sampling stac items of area ~250km^2; results in ~\n",
    "    # apply the common h3 index to both of our tables\n",
    "    ddb_alter_table_add_h3(\n",
    "        db_file=out_consolidated_db,\n",
    "        table_name=TABLE_NAME,\n",
    "        h3_resolution=common_h3_res\n",
    "    )\n",
    "\n",
    "    ddb_alter_table_add_h3(\n",
    "        db_file=out_consolidated_db,\n",
    "        table_name=ov_divisions_table,\n",
    "        h3_resolution=common_h3_res\n",
    "    )\n",
    "\n",
    "    # close the db connection since we are about to add some new tables that don't automatically reflect in the db object\n",
    "    conn.close()\n",
    "\n",
    "    # use our util to add the matching overture divisions to our pv labels\n",
    "    h3_col = f\"h3_res_{common_h3_res}\"\n",
    "    joined_divs = ddb_save_div_matches(\n",
    "        db_file=out_consolidated_db,\n",
    "        labels_table=TABLE_NAME,\n",
    "        divisions_table=ov_divisions_table,\n",
    "        division_subtypes=division_types,\n",
    "        h3_col_name=h3_col\n",
    "    )\n",
    "    if joined_divs:\n",
    "        print(\"Joined Overture divisions with PV labels successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to join Overture divisions with PV labels. See errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TdKRQf3nHm2i",
   "metadata": {
    "editable": true,
    "id": "TdKRQf3nHm2i",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    %config SqlMagic.feedback = False\n",
    "    %config SqlMagic.displaycon = False\n",
    "    conn = get_duckdb_connection(db_file)\n",
    "    %sql conn --alias duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "El4HeRzUFkoJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "bc73779cfa8c416d819a996ed53c24bd",
      "022019ddcc4f462b951d7de46ed02101",
      "1f5e4805d484460584afc94d4d247fa9"
     ]
    },
    "editable": true,
    "id": "El4HeRzUFkoJ",
    "outputId": "af13840a-8459-4ad2-b58d-14bfc42dfe50",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "overture_divisions_table = os.getenv(\"DIVISIONS_DB_TABLE\", \"overture_division_areas\")\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # save the geometries for countries in a separate table with some pv labels aggregate stats\n",
    "    saved_country_geoms = ddb_save_subtype_geoms(db_file=db_file,\n",
    "                                                div_table=overture_divisions_table,\n",
    "                                                pv_table=TABLE_NAME,\n",
    "                                                division_type='country')\n",
    "    if saved_country_geoms:\n",
    "        print(f\"Saved all country geometries in separate table `ov_divisions_country_geoms`\")\n",
    "    else:\n",
    "        print(\"Failed to save country geometries with PV labels. See errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693094ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "editable": true,
    "id": "693094ca",
    "outputId": "f3243c7b-1c66-4241-a746-39167f840bf1",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql DESCRIBE country_geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b2b79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "editable": true,
    "id": "5e7b2b79",
    "outputId": "c882349d-41d3-4a87-cce0-e2a1dda708b4",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql SUMMARIZE SELECT country_iso, division_name, country_pv_count, country_pv_area_m2 FROM country_geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d35328",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "editable": true,
    "id": "36d35328",
    "outputId": "0401fba2-871e-4edd-df70-92d0acac9fbf",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get country geoms in gdf\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "countries_query = f\"\"\"\n",
    "SELECT division_id, country_iso, division_name, country_pv_count, country_pv_area_m2, ST_AsText(geometry) AS geometry\n",
    "FROM country_geoms;\"\"\"\n",
    "country_gdf = conn.sql(countries_query).df()\n",
    "# convert the geometry column from WKT to shapely geometries\n",
    "country_gdf = gpd.GeoDataFrame(country_gdf, geometry=country_gdf['geometry'].apply(wkt.loads), crs=\"EPSG:4326\")\n",
    "\n",
    "# Convert area from m² to km²\n",
    "country_gdf['country_pv_area_km2'] = country_gdf['country_pv_area_m2'] / 1_000_000\n",
    "\n",
    "# plot chloropleth map of the country geoms colored by the number of PV installations\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 7))\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"left\", size=\"5%\", pad=0.1)\n",
    "\n",
    "country_gdf.plot(column='country_pv_area_km2', ax=ax,\n",
    "    cmap='viridis', linewidth=0.8, edgecolor='0.8',\n",
    "    legend=True, cax=cax, vmin=0, vmax=country_gdf['country_pv_area_km2'].max(),\n",
    "    legend_kwds={'label': \"Total Area (km²)\",\n",
    "                 'orientation': \"vertical\", 'shrink': 0.5, 'aspect': 30,\n",
    "                 'ticks': [0, 10, 25, 50, 100, 150, 175, 200]})\n",
    "ax.set_title('Aggregate Area of Installed PV Capacity by Country (km²)', fontdict={'fontsize': '25', 'fontweight' : '3'})\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ad710",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "id": "b29ad710",
    "outputId": "d8203fb3-c421-477a-d156-22b37d144a0b",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample PV installations for visualization\n",
    "pv_gdf = viz_gdf.sample(39000, random_state=42)\n",
    "# prepare interactive scatterplot map with Folium\n",
    "map = folium.Map(location=[66.5901, 18.2208], zoom_start=1, tiles='OpenStreetMap',\n",
    "                height=800, width=1200, legend=True)\n",
    "pv_gdf.explore(column='dataset', m=map, legend=True, cmap='inferno', popup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94a7cd",
   "metadata": {
    "editable": true,
    "id": "2b94a7cd",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Querying and Searching STAC Collections\n",
    "\n",
    "- **S**patio**T**emporal **A**sset **C**atalog (STAC).\n",
    "- Standardized specification for describing geospatial information.\n",
    "- Enables searching and discovery of EO data (imagery, etc.) across different catalog providers (e.g. Microsoft Planetary Computer, AWS Open Data, Google Earth Engine, etc.)\n",
    "- STAC collections are a standardized way to describe datasets, including metadata, spatial and temporal extents, and links to assets.\n",
    "- Key concepts:\n",
    "    - **STAC Item**: Represents a single observation or asset, including metadata and links to assets (e.g., images, metadata files).\n",
    "    - **STAC Collection**: A collection of STAC items and collections, organized hierarchically.\n",
    "    - **STAC Catalog**: A collection of STAC items and collections, organized hierarchically.\n",
    "    - **STAC API**: RESTful API for searching and retrieving STAC items and collections.\n",
    "    - **STAC Browser**: Web-based interface for exploring and visualizing STAC collections.\n",
    "- Libraries like `pystac-client` facilitate programmatic searching based on spatial (bbox, geometry) and temporal criteria.\n",
    "    - STAC API supports CQL (Common Query Language) for complex queries over catalog fields (e.g. `datetime` in range, `eo:cloud_coverage` < 20%, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc4456",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "editable": true,
    "id": "ddbc4456",
    "outputId": "1f31f932-f60e-43d3-a866-6dcd640d2df8",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('report/assets/figures/maxar_stac_demo_tile_footprints.gif', width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a6846",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "editable": true,
    "id": "2e1a6846",
    "outputId": "e86da3f2-de4c-4c2b-cf97-b76fe61b9191",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('report/assets/figures/maxar_stac_raster_demo.gif', width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab7207c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "editable": true,
    "id": "9ab7207c",
    "outputId": "e7b2a54e-d469-47fb-82df-5aaf340d9f7a",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"https://radiantearth.github.io/stac-browser/#/external/maxar-opendata.s3.amazonaws.com/events/catalog.json?.language=en\", width=1080, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e3a1c",
   "metadata": {
    "editable": true,
    "id": "341e3a1c",
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Xarray and ND-arrays in Scientific Computing\n",
    "\n",
    "- Xarray introduces labels (dimensions, coordinates, attributes) to multi-dimensional arrays (like NumPy's ndarray).\n",
    "- ND-arrays are common in climate science, oceanography, and remote sensing that require analysis of multi-dimensional data.\n",
    "- **Benefits for Geospatial/EO Data:**\n",
    "  - Handles complex data like satellite image time series (e.g., dimensions: time, band, y, x).\n",
    "  - Facilitates operations like alignment, indexing, and aggregation based on labels (e.g., time series analysis, **operations over multispectral bands**).\n",
    "  - Integrates well with Dask for **parallel computing on large datasets**\n",
    "- **Xarray + Dask:** Enables parallel processing of large datasets, leveraging Dask's task scheduling and lazy evaluation.\n",
    "- **Xarray + GeoParquet:** Enables efficient reading/writing of geospatial data in Parquet format, leveraging Xarray's capabilities for handling multi-dimensional data.\n",
    "- **Xarray + STAC:** Enables easy access to EO data stored in STAC collections, allowing for efficient querying and analysis of large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74049d8e",
   "metadata": {
    "editable": true,
    "id": "74049d8e",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The Critical Role of Virtualization in Cloud Advances\n",
    "\n",
    "- **Foundation of Cloud Computing:** Allows abstraction of physical hardware (networks, storage, compute, you name it!) into virtual, ephemeral resources.\n",
    "- **Resource Pooling & Elasticity:** Enables efficient sharing and dynamic allocation/scaling of compute, storage, and network resources centralized in data centers distributed across the globe.\n",
    "- **Separation of Concerns:** Decouples applications from **underlying infrastructure**, allowing developers to focus on building applications without worrying about hardware management and reproducibility across environments.\n",
    "- **Cost Efficiency:** Pay-as-you-go model for resources, reducing upfront costs and allowing for on-demand scaling.\n",
    "    - Cloud providers offer flexible pricing models (on-demand, reserved, spot instances).\n",
    "    - Be aware of potential vendor lock-in and hidden costs that can impact long-term economics.\n",
    "    - **Computational Scale:** Access to dirt-cheap storage and massive computing resources on demand without infrastructure management overhead.\n",
    "- **Enabler for:**\n",
    "  - Infrastructure as a Service (IaaS), Platform as a Service (PaaS), Software as a Service (SaaS).\n",
    "  - Modern data architectures (Data Lakes, Lakehouses)\n",
    "  - **Serverless computing**\n",
    "    - - **Making Big Data Cheap:** Easily scale resources up or down as needed, enabling rapid deployment and cost-effective huge analytical workloads.\n",
    "    - easier to scale and manage briefly as needed for analysis\n",
    "        - e.g. no need to keep a high-availability cluster with replicas and failover running 24/7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976f48c",
   "metadata": {
    "editable": true,
    "id": "1976f48c",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Rise of Virtual Datasets in EO\n",
    "\n",
    "- **Concept:** Datasets defined by *references* to data assets stored elsewhere (usually cloud object storage), rather than containing the data itself.\n",
    "    - Pointers or references, but for TB's of scientific data.\n",
    "    - These formats create lightweight indexes that map to specific byte ranges in cloud-stored files.\n",
    "- **Benefits:**\n",
    "        - Avoids data duplication and large data transfers.\n",
    "        - Allows analysis of data *in place*.\n",
    "        - Facilitates sharing and collaboration without transferring large datasets.\n",
    "        - Enables rapid development of derivative data products from huge raw data.\n",
    "- **Impact:** Enables efficient analysis of massive planetary-scale archives (e.g., climate models, satellite imagery) directly from cloud storage.\n",
    "- **Examples:**\n",
    "  - **Kerchunk:** Creates reference files that map logical chunks (e.g., in Xarray) to byte ranges in cloud storage. Allowing libraries like Xarray to read cloud data **as if it were a single local file**\n",
    "      - completely serverless architecture: asynchronous concurrent fetching, parallel access to multiple files, and lazy loading of data\n",
    "      - supports reading from all of the storage backends supported by fsspec (s3, gcs, abfs, etc), http, cloud user storage (dropbox, **gdrive**) and network protocols (ftp, ssh, hdfs, smb…)\n",
    "      - default JSON schema can be slow to load and heavy on memory → **supports exporting references as [parquet files](https://fsspec.github.io/kerchunk/spec.html#parquet-references)** for efficient storage and retrieval\n",
    "  - **VirtualiZarr:** Similar concepts for creating virtual Zarr datasets via Kerchunk references.\n",
    "  - **Icechunk:** A rising file format based on Apache Iceberg for chunked data access in cloud storage, enabling efficient reading of large datasets without downloading them entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb55917",
   "metadata": {
    "editable": true,
    "id": "5cb55917",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Hierarchical Spatial Clustering:\n",
    "\n",
    "- **Hierarchical Clustering:**  \n",
    "  Groups data points into a hierarchy of clusters.\n",
    "- **Spatial Clustering:**  \n",
    "  Groups data points based on their spatial proximity.\n",
    "- **Hierarchical Spatial Clustering:**  \n",
    "  Combines both concepts, creating a hierarchy of clusters based on spatial relationships.\n",
    "- **Benefits:**\n",
    "  - Captures multi-scale spatial patterns.\n",
    "  - Provides a hierarchical structure for data exploration and analysis.\n",
    "  - Useful for large datasets with varying spatial resolutions.\n",
    "\n",
    "  <figure style=\"text-align: center\">\n",
    "  <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/clustering_simple_example.jpg?raw=1\" style=\"width:50%;\">\n",
    "  <figcaption align = \"center\"> Example of hierarchical clustering with 6 clusters and ≥ 2 hierarchical levels </figcaption>\n",
    "  </figure>\n",
    "\n",
    "  <!-- ## Hierarchical Spatial Clustering:\n",
    "\n",
    "<!-- <div style=\"display: flex; flex-direction: row; align-items: flex-start;\">\n",
    "    <div style=\"flex: 2; padding-right: 20px;\">\n",
    "        <ul>\n",
    "            <li> Different sensors capture different types of data.</li>\n",
    "            <li> Each sensor has its own characteristics and applications.</li>\n",
    "            <li> <strong>Hierarchical Clustering:</strong>:   Groups data points into a hierarchy of clusters. </li>\n",
    "            <li> <strong>Spatial Clustering:</strong> Groups data points based on their spatial proximity. </li>\n",
    "            <li> <strong>Hierarchical Spatial Clustering:</strong> Combines both concepts, creating a hierarchy of clusters based on spatial relationships. </li>\n",
    "            <li> <strong>Benefits:</strong> (4-15 bands) </li>\n",
    "                <ul>\n",
    "                    <li> Captures multi-scale spatial patterns.</li>\n",
    "                    <li> Provides a hierarchical structure for data exploration and analysis.</li>\n",
    "                    <li> Useful for large datasets with varying spatial resolutions.</li>\n",
    "                </ul>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"flex: 1;\">\n",
    "        <figure style=\"text-align: center\">\n",
    "        <img src=\"report/assets/figures/clustering_simple_example.jpg\" style=\"height:120%;\">\n",
    "        <figcaption align = \"center\"> Example of hierarchical clustering with 6 clusters and ≥ 2 hierarchical levels </figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "</div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee5696",
   "metadata": {
    "editable": true,
    "id": "7bee5696",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### \"Clustering with Minimum Spanning Trees: How good can it be?\" (2024)\n",
    "\n",
    "- **Definition:** A Minimum Spanning Tree (MST) of a connected, undirected graph is a subgraph that:\n",
    "    - connects *all* the graph vertices together\n",
    "    - has *no cycles*\n",
    "    - minimizes total *edge weights* for the subgraph\n",
    "- For a given dataset, an MST can represent relationships between data points, where edge weights often correspond to distances between points (e.g. Euclidean for low-dimensional data)\n",
    "- Relevant Properties:\n",
    "    - An MST for n points vertices will **always have n-1 edges**\n",
    "    - **Removing k-1 edges** from an MST results in **k connected components**, which can be interpreted as clusters\n",
    "    - MSTs are effective in detecting well-separated clusters of **arbitrary shapes**, and, unlike K-means and other clustering algorithms, **doesn't require strong assumptions nor a priori knowledge about the data** like convexity or knowing number of clusters\n",
    "- **Why?:**:\n",
    "    * Natural cluster representation: MSTs offer an attractive and convenient representation of datasets for clustering.\n",
    "    * Versatility: Detects clusters of varying densities and arbitrary shapes (see fig)\n",
    "    * Foundation for various clustering algorithms (single linkage, divisive, agglomerative).\n",
    "    * Performance: see next slide\n",
    "\n",
    "<!-- display MST cluster examples -->\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/mst_arbitrary_clusters.png?raw=1\" style=\"width:40%; height:40%;\">\n",
    "<figcaption align = \"center\"> MST to Cluster examples </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4cc810",
   "metadata": {
    "editable": true,
    "id": "7d4cc810",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Clustering with MSTs: Construction and Running Times\n",
    "\n",
    "- **Running Times:** MSTs are relatively fast to (pre)compute. Classical algorithms include:\n",
    "    * *Borůvka's algorithm (1926):* Typically $O(mlog n)$ for graphs with m edges and n vertices. For dense graphs, $m \\thickapprox n^2$ → $O(n^2 log n)$.\n",
    "    * *Jarník's (1930) / Prim's (1957) algorithm:* Can be implemented with a Fibonacci heap to achieve $O(m + n log n)$. For dense graphs, it's $O(n^2),$.\n",
    "    * *Kruskal's algorithm (1956):* Requires sorting all edges, leading to $O(mlogm)$ or $O(mlogn)$. For dense graphs, this is $O(n logn)$.\n",
    "\n",
    "- **Performance**: From their benchmarking results, the authors of the paper note:\n",
    "    * \"As far as the current benchmark battery is concerned, the MST-based methods outperform the popular “parametric” approaches (Gaussian Mixtures, K-means) and other algorithms (Birch, Ward, Average, Complete linkage, and spectral clustering with proper parameters) implemented in the **scikit-learn package**\"\n",
    "    * \"[MST Clustering methods] are quite simple and easy to compute: once the minimum spanning tree is considered (which takes up to O(n2) time, but approximate methods exist as well) we can potentially **get a whole hierarchy of clusters of any cardinality**\"\n",
    "        - \"For instance, our top performer...needs $O(n√n)$ to generate *all possible partitions* given a prebuilt MST\" -->\n",
    "- **MST Approximations:** Can also be computed for further speed-ups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a1206c",
   "metadata": {
    "editable": true,
    "id": "45a1206c",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Discrete Global Grid Systems and Geospatial Indexing\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/Icosahedron-dggs-sphere-projections.png?raw=1\" style=\"width:33%;\">\n",
    "<figcaption align = \"center\"> (a) Icosahedron faces projected onto a sphere (b) Triangular tessellation (c) Diamond tessellation, (d) Hexagonal tessellation, (e) Square tessellation, (f) Aperture 3 grid, (g) Aperture 4 grid, (h) Aperture 7 grid, (i-k) Projected Icosahedron faces with different pole orientations  </figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87835c0",
   "metadata": {
    "editable": true,
    "id": "b87835c0",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### DGGS and H3\n",
    "<!-- From their [home page](https://h3geo.org/), [announcement blog](https://www.uber.com/blog/h3/), and [overview page](https://h3geo.org/docs/core-library/overview/): -->\n",
    "- **What:** A **discrete global grid system** (DGGS) divides the Earth's surface into a hierarchy of grid cells (e.g. square, hexagon), providing a consistent global framework for indexing and clustering geospatial data.\n",
    "- **H3 DGGS:**\n",
    "    * The H3 geospatial indexing system is a DGGS developed at Uber (2018)\n",
    "    * It was designed for indexing geographies via multi-resolution tiling into a **hexagonal grid with hierarchical indexes**.\n",
    "        - Advantages of Hexagons: Uniform neighbor distances, good for spatial calculations, built-in grid functions for distances and traversal\n",
    "        - hierarchical hexagon structure and choice of projection while performant, establishes **some inherent limitations in spatial accuracy and precision**\n",
    "    * **Geospatial coords can be indexed to cell IDs** at diff. resolutions (0-15) that each represent a *unique cell* in the grid *at each resolution*.\n",
    "    * Natural clustering of PoIs/RoIs within H3's hierarchy\n",
    "        - The hexagonal grid system is **designed to be hierarchical**, meaning that each cell at a given resolution can be subdivided into 7 smaller cells at higher resolutions, allowing for efficient spatial queries and analysis.\n",
    "\n",
    "   \n",
    "<!-- It is common to use WGS84/EPSG:4326 CRS data with the H3 library. -->\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=100,onerror=redirect,format=auto/wp-content/uploads/2018/06/Twitter-H3.png\" style=\"width:75%; height:50%;\">\n",
    "<figcaption align = \"center\"> H3 enables users to partition the globe into hexagons for more accurate analysis. </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135acda5",
   "metadata": {
    "editable": true,
    "id": "135acda5",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "- **Benefits for Spatial Analysis:**\n",
    "  - *Fast Joins & Aggregation:* Quickly combine data across datasets based on cell ID.\n",
    "  - *Efficient Neighborhood Queries:* Hexagons have uniform adjacency and H3 provides a built-in Grid Traversal API with distance metrics.\n",
    "  - *Hierarchical Structure:* Easy aggregation/disaggregation across resolutions (parent/child cells).\n",
    "  - *Optimized Grid Traversal:* Useful for spatial algorithms.\n",
    "  - **Foundation for spatial indexing and clustering in this work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2073c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "editable": true,
    "id": "8f2073c9",
    "outputId": "7c442f95-cd05-44d5-cb4b-b6228a646964",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "# display h3 viewer\n",
    "IFrame(\"https://h3.chotard.com\", width=1080, height=540)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5795b",
   "metadata": {
    "editable": true,
    "id": "11b5795b",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Application in \"Planning for Earth Imaging Tasks via Grid Significance Mapping\" (2024)\n",
    "\n",
    "- proposes using H3 to uniformly map Points of Interest (PoIs) and Regions of Interest (RoIs) for EO satellite **future** task planning\n",
    "- Appropriate H3 resolutions (e.g., 6 and 7) are chosen so grid cell sizes are relevant to **satellite strip widths** (10s-100s of km's) for better planning\n",
    "- introduces a method to calculate the \"significance\" or importance of each grid cell based on the POI's it contains\n",
    "    * Algorithm 1: *Significance mapping of PoIs within a grid*:\n",
    "        1. Takes all POIs in a grid and their weights, and a user-defined \"significance\" metric as input.\n",
    "        2. Forms a histogram of POI weights and iteratively selects top weighted levels based on the significance metric.\n",
    "        3. The higher the significance level, the more the grid's significance relies on high-priority POIs. **This allows users to customize how high-priority POIs dominate the grid significance calculation.**\n",
    "            - e.g. for our case, PV panel area for coarser resolution imagery, or ratio of location's panel density over total area for finer resolution imagery\n",
    "        4. This results in a \"heatmap\" of requirement distributions where warmer colors indicate more important grid cells.\n",
    "- these and other authors note how clustering data in grids lends itself for **trivial parallelization**\n",
    "- Our proposed twist is **Let's flip the time dimension!:**\n",
    "    *  Instead of planning **new** image acquisitions, this grid significance scheme can be used to **optimize queries to STAC** archives for **existing imagery**\n",
    "    * **Objective:** *Maximize overlap* of your H3 grid cells with *Raster asset footprints* while *minimizing the number of queries* and downloaded STAC assets.\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/h3_dggs_EO_tasks.png?raw=1\" style=\"width:70%; height:60%;\">\n",
    "<figcaption align = \"center\"> H3 DGGS for EO tasks </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66548e9f",
   "metadata": {
    "editable": true,
    "id": "66548e9f",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Contributions in \"HierGP: Hierarchical Grid Partitioning for Scalable Geospatial Data Analytics\" (2025)\n",
    "\n",
    "- **HierGP**: Introduces a Hierarchical Grid Partitioning (HierGP) framework that dynamically adapts to dataset's spatio-temporal characteristics.\n",
    "    * Square grid aligns well with satellite pixel data\n",
    "    * This differs from traditional fixed DGGS (which conventionally use a non-adaptive grid system or a fixed resolution) in some important ways:\n",
    "        - *Adaptive Grid Sizing:* recursive patitioning method allows the grid to dynamically adapt to the data's distribution and density in *each* local region\n",
    "        - *Data-drive Partitioning:* Beyond using only geographical criteria, it incorporates general data features like variance and clustering to make better partitioning decisions. Particularly relevant for highly heterogeneous datasets.\n",
    "        - *Handling of Large Datasets:* Built with parallelization and mini-batch processing in mind to enhance scalability and performance.\n",
    "        - *Multi-resolution and Multi-dimensional Support:* Can be used for time-series data and higher-dimensional data (e.g. 3D depth data).\n",
    "- Relevant contributions:\n",
    "    * **Map Point Reduction:**\n",
    "        - *Objective:* reduce the number of unique coordinate points in a large dataset so that similar points can be grouped together *and be accurately represented by a single point*.\n",
    "        - *Method:* aggregates and collapses data points based on user-defined similarity criteria and grid size.\n",
    "        - *Performance:* has linear time complexity $O(n)$ where n is the number of unique samples.\n",
    "    * **Temporal Partitioning:** A method for partitioning data based on time, allowing for the analysis of temporal patterns and trends.\n",
    "        - Calculates $k$ partitions based on $\\tau_{max}$ and $\\tau_{min}$ datetime values, and the dataset's temporal resolution (frequency).\n",
    "        - *Performance:* $O(1)$ one-time calculation for the dataset. Trivially vectorized.\n",
    "    * **Performance benchmark against most popular DGGS's:**\n",
    "        - Outperforms H3, S2, GeoHash in runtime, memory, scalability in their tests.\n",
    "        - Case Studies:\n",
    "            * Environmental Health: Analyzed *289M+ location points* for ~350 individuals\n",
    "            * NDVI Extraction for Large Polygons (US Counties)\n",
    "        - H3 almost always outperformed S2 and GeoHash in their tests, but HierGP was faster than H3 in most cases.\n",
    "        - H3 offers a much more mature development ecosystem and is more widely adopted, but the authors provide their concise Python implementation of HierGP in [Github](https://github.com/funsooje/HierarchicalGridPartitioning/tree/main)\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/hierGP_dggs_benchmark.png?raw=1\" style=\"width:75%; height:auto;\">\n",
    "<figcaption align = \"center\"> HierGP vs DGGS Benchmarks </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e33e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "39ddeb74f08e44c784a3d4b4086e7678",
      "dedd92403c5b4cd79359b27ea9bb0d9f",
      "30723e35528142b997392517cedceb4b"
     ]
    },
    "editable": true,
    "id": "1a2e33e8",
    "outputId": "348e199e-3658-4230-90d0-4ba054ead008",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# add a common h3 index at the same resolution to both our pv labels and overture divisions for easier spatial joins\n",
    "common_h3_res = 5 # ~250km^2; roughly corresponds to many sensors swath widths, and San Juan, PR is ~200km^2\n",
    "# common_h3_res = 4 # ~1770km^2; children cells can be used for sampling stac items of area ~250km^2; results in ~\n",
    "\n",
    "# apply the common h3 index to both of our tables\n",
    "ddb_alter_table_add_h3(\n",
    "    db_file=out_consolidated_db,\n",
    "    table_name=TABLE_NAME,\n",
    "    h3_resolution=common_h3_res\n",
    ")\n",
    "\n",
    "ddb_alter_table_add_h3(\n",
    "    db_file=out_consolidated_db,\n",
    "    table_name=overture_divisions_table,\n",
    "    h3_resolution=common_h3_res\n",
    ")\n",
    "\n",
    "# close the db connection since we are about to add some new tables that don't automatically reflect in the db object\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383f796",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "0d8247fa378c4ad282531b1525fac626",
      "58311f5d59144cde8af1177eaee3acd0",
      "e969b64e3e78485ab395d1baa56393ab"
     ]
    },
    "editable": true,
    "id": "1383f796",
    "outputId": "db2383ed-f8d8-4acc-d4ed-9773f363eb43",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use our util to add the matching overture divisions to our pv labels\n",
    "h3_col = f\"h3_res_{common_h3_res}\"\n",
    "division_types = [\"country\", \"region\"]\n",
    "joined_divs = ddb_save_div_matches(\n",
    "    db_file=out_consolidated_db,\n",
    "    labels_table=TABLE_NAME,\n",
    "    divisions_table=overture_divisions_table,\n",
    "    division_subtypes=division_types,\n",
    "    h3_col_name=h3_col\n",
    ")\n",
    "if joined_divs:\n",
    "    print(\"Joined Overture divisions with PV labels successfully.\")\n",
    "else:\n",
    "    print(\"Failed to join Overture divisions with PV labels. See errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c1621",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "editable": true,
    "id": "4d7c1621",
    "outputId": "8036ada8-bde6-4c34-9a61-3243e3ce213b",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reload the db connection we closed earlier\n",
    "conn = get_duckdb_connection(db_file)\n",
    "%sql conn --alias duckdb\n",
    "\n",
    "print(f\"Updated columns for DuckDB table `{TABLE_NAME}` with matching overture divisions fields:\\n\")\n",
    "%config SqlMagic.autopandas = False\n",
    "%sql SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfbce4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "editable": true,
    "id": "adfbce4c",
    "outputId": "6b564f49-0dfb-4199-ec0e-cd5a95b4f9f6",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"\\n\\nUpdated columns for DuckDB table `{TABLE_NAME}` with matching overture divisions fields:\\n\")\n",
    "%sql DESCRIBE {{TABLE_NAME}};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382a9dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "editable": true,
    "id": "7382a9dc",
    "outputId": "472e3b1a-1883-4d3d-c110-aa3fd59fccb4",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql SUMMARIZE SELECT unified_id, dataset, area_m2, centroid_lon, centroid_lat, bbox, {{h3_col}}, division_id, division_name FROM {{TABLE_NAME}} WHERE {{h3_col}} IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb4dc5",
   "metadata": {
    "editable": true,
    "id": "10cb4dc5",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Unlocking  $Unbounded^*$ $Parallelism$ for Clustering with $MST's$\n",
    "\n",
    "<div style=\"display: flex; flex-direction: row; align-items: flex-start; gap: 20px;\">\n",
    "    <!-- Left Column -->\n",
    "    <div style=\"flex: 1;\">\n",
    "        <figure style=\"text-align: right; margin-top: 25%;\">\n",
    "            <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/parallelism_predators_analogy.jpg?raw=1\" style=\"width:80%;\">\n",
    "            <figcaption align=\"center\" style=\"font-size: 0.8em;\">Analogy for strengths and weaknesses of Parallel Programming</figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "    <!-- Right Column -->\n",
    "    <div style=\"flex: 1; display: flex; flex-direction: column; gap: 20px;\">\n",
    "        <!-- Right Column - Top Row -->\n",
    "        <figure style=\"text-align: left; margin: 0;\">\n",
    "            <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/Amdahls_law_viz.jpeg?raw=1\" style=\"width:70%;\">\n",
    "            <figcaption align=\"left\" style=\"font-size: 0.8em;\">Upper bounds relative to program's parallelism % and diminishing returns on increasing cores established by Amdahl's Law</figcaption>\n",
    "        </figure>\n",
    "        <!-- Right Column - Bottom Row -->\n",
    "        <figure style=\"text-align: left; margin: 0;\">\n",
    "            <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/typical-parallelism-speed-up-graph-and-Amdahls-law-upper-bound.png?raw=1\" style=\"width:70%;\">\n",
    "            <figcaption align=\"left\" style=\"font-size: 0.8em;\">Amdahl's Law upper bound vs Typical in-practice speed-up graph</figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd06d7",
   "metadata": {
    "editable": true,
    "id": "7ddd06d7",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### *\"Fast Parallel Algorithms for Euclidean MST and Hierarchical Spatial Clustering\"* (2021)\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "    <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/parallel_hdbscan_motivation.png?raw=1\" style=\"width:90%;\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0036038",
   "metadata": {
    "editable": true,
    "id": "e0036038",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Parallel $HDBSCAN^*$    \n",
    "\n",
    "<div style=\"display: flex; flex-direction: row; align-items: flex-start; gap: 20px;\">\n",
    "    <!-- Left Column -->\n",
    "    <div style=\"flex: 3; padding-right: 20px;\">\n",
    "    <ul>\n",
    "        <li><strong>Main Contributions:</strong>\n",
    "            <ul>\n",
    "                <li>Presents new <em>parallel algorithms</em> for <strong>EMST</strong> and Hierarchical Density-Based Spatial Clustering of Applications with Noise (<strong>HDBSCAN</strong>).\n",
    "                    <ul>\n",
    "                        <li><strong>Theorem:</strong> Given a set of $n$ points, we can compute the $MST$ on the mutual reachability graph in $O(n^2)$ work, $O(log^2 n)$ depth, and $O(n·minPts)$ space.\n",
    "                            <ul>\n",
    "                                <li>minPts is the \"density\" parameter for HDBSCAN</li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>Work (number of operations) matches SOTA sequential counterparts, but with a <strong>parallel speedup of at least 11x</strong> on 48 cores.</li>\n",
    "                <li>Parallel dendogram construction and clustering algorithms are provided.\n",
    "                    <ul>\n",
    "                        <li>a classic key step in single-linkage clustering algorithms</li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>They provide their implementation in C++ with Python bindings in <a href=\"https://github.com/wangyiqiu/hdbscan\">Github</a></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Parallel Algorithms bring extra challenges at design stage:</strong>\n",
    "            <ul>\n",
    "                <li><em>Load Balancing:</em> Ensuring that all processors have roughly equal workloads to avoid idle time and maximize parallel speedup.</li>\n",
    "                <li><em>Communication Overhead:</em> Minimizing the amount of data exchanged between processors to reduce latency and improve performance.\n",
    "                    <ul>\n",
    "                        <li>\"Under the hood\", requires efficient coordination and synchronization across processors</li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li><em>Partitioning Work:</em> Dividing the data into smaller chunks that can be processed independently and in parallel.</li>\n",
    "                <li><em>Data Locality:</em> Ensuring that data is stored and accessed in a way that minimizes memory access times by maximizing use of local caches</li>\n",
    "                <li><em>and many more...</em></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Brief notes on designing and analyzing Parallel Algorithms:</strong>\n",
    "            <ul>\n",
    "                <li>Algorithms are commonly represented as directed acyclic graphs (DAGs) where:\n",
    "                    <ul>\n",
    "                        <li>Nodes represent operations or tasks</li>\n",
    "                        <li>Edges represent dependencies between tasks</li>\n",
    "                        <li>i.e. Nodes with no incoming edges can be executed in parallel</li>\n",
    "                        <li>i.e. Nodes with incoming edges must wait for their dependencies to be completed before they can be executed</li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>Work:\n",
    "                    <ul>\n",
    "                        <li>The total number of operations performed by the algorithm.</li>\n",
    "                        <li>For parallel algorithms, work is often expressed as a function of the number of processors used.</li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>Depth:\n",
    "                    <ul>\n",
    "                        <li>The maximum depth (longest path of root to leaf) of the DAG representing the longest dependency chain.</li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "    </div>\n",
    "    <!-- Right Column -->\n",
    "    <div style=\"flex: 1;\">\n",
    "        <figure style=\"text-align: center; margin: 0;\">\n",
    "            <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/parallel_hdbscan_contributions.png?raw=1\" style=\"height:70%; width: 90%;\">\n",
    "        </figure>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b451b",
   "metadata": {
    "editable": true,
    "id": "aa4b451b",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Parallel EMST Construction and Dendogram SLC Bottleneck\n",
    "<div style=\"display: flex; flex-direction: row; align-items: flex-start; gap: 20px;\">\n",
    "    <!-- Left Column -->\n",
    "    <div style=\"flex: 3; padding-right: 20px;\">\n",
    "        <ul>\n",
    "            <li><strong>Approach:</strong>\n",
    "                <ul>\n",
    "                    <li><strike>Parallel Construction of a Well-Separated Pair Decomposition (WSPD) of the input points</strike> H3 provides an <em>inherent</em> clustering of PoIs/RoIs:\n",
    "                        <ul>\n",
    "                            <li>Instead of WSPD identifying pairs of point sets, our H3 grid inherently defines spatial groupings at different resolutions. (e.g. k-nearest grid cells)</li>\n",
    "                            <li> H3 provides buit-in grid traversal methods that provide a distance in H3 cells between two grid cells</li>\n",
    "                            <li> We can use these distances to generate a similar Mutual Reachability Graph (MRG) as described in the paper that feeds edges into the MST construction.</li>\n",
    "                            <li> We can expect the same run-time performance as the WSPD approach, but with a much lower memory footprint and trivial parallelization.</li>\n",
    "                        </ul>\n",
    "                    </li>\n",
    "                    <li><strong>Builds an EMST</strong> from an MRG using a variant of Kruskal's algorithm, GeoFilterKruskal, that intelligently selects and processes potential edges in parallel, without necessarily materializing all possible pairs upfront:\n",
    "                        <ul>\n",
    "                            <li>Iterative Edge Consideration: The algorithm works in batches of edges to build the MST.</li>\n",
    "                            <li>Prioritizes \"Cheaper\" Potential Edges with an increasing parameter <code>&beta;</code> that limits the size of points groupings being considered each round:\n",
    "                                <ul>\n",
    "                                    <li>focuses on identifying edges between small, nearby groups of points (or H3 cells in our case) first.</li>\n",
    "                                    <li>edges connecting very close and small clusters are more likely to be part of the MST and are computationally cheaper to evaluate</li>\n",
    "                                    <li>to avoid processing edges that are clearly too long, it establishes an upper bound on edge weights</li>\n",
    "                                </ul>\n",
    "                            </li>\n",
    "                            <li>Parallel Edge Processing &amp; MST Construction:\n",
    "                                <ul>\n",
    "                                    <li><strike>exact Euclidean distances</strike> <code>h3.grid_distance(h1, h2)</code> are computed for candidate edges in parallel</li>\n",
    "                                    <li>these edges are then fed into a parallel Kruskal's MST algorithm (or a similar component using a <strong>Union-Find data structure</strong>)</li>\n",
    "                                    <li>adds edges to the growing MST if they connect previously disconnected components</li>\n",
    "                                    <li>filtering future edge candidates: if the points that a potential edge would connect are already in the current MST, the edge is ignored and distance calculation is skipped</li>\n",
    "                                </ul>\n",
    "                            </li>\n",
    "                            <li>Parallel refinement:\n",
    "                                <ul>\n",
    "                                    <li>the algorithm iterates, expanding the size of point groupings considered (increasing &beta;) and updating the edge weight upper bound</li>\n",
    "                                    <li>this continues <strong>until n&minus;1 edges are added to form the complete MST</strong></li>\n",
    "                                    <li>steps are designed for parallel execution</li>\n",
    "                                </ul>\n",
    "                            </li>\n",
    "                        </ul>\n",
    "                    </li>\n",
    "                    <li><strike>Parallel Dendogram Construction</strike>\n",
    "                        <ul>\n",
    "                            <li>in standard HDBSCAN and this parallel variant, the MST is used to build a dendrogram, the data structure that enables hierarchy exploration and stability analysis</li>\n",
    "                            <li>this is achieved by using the edges of the MST to define the hierarchical relationships between the points</li>\n",
    "                            <li>However, for our application, H3, again, <em>inherently</em> defines a hierarchical structure for h3 grid cells (our \"points\") at different resolutions!:\n",
    "                                <ul>\n",
    "                                    <li>H3 itself is a <em>hierarchical spatial index</em>. It has <strong>built-in parent-child relationships between cells</strong> at different resolutions.</li>\n",
    "                                    <li><code>h3.h3_to_parent(h3_address, resolution)</code> and <code>h3.h3_to_children(h3_address, resolution)</code> operations provide our hierarchical structure.</li>\n",
    "                                </ul>\n",
    "                            </li>\n",
    "                        </ul>\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <!-- Right Column -->\n",
    "    <div style=\"flex: 1;\">\n",
    "        <figure style=\"text-align: center; margin: 0;\">\n",
    "            <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/parallel_hdbscan_approach_outline.png?raw=1\" style=\"width:100%;\">\n",
    "        </figure>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Dendogram and adapting HDBSCAN* to H3 Caveats:\n",
    "Mutual Reachability: Standard HDBSCAN uses \"core distances\" and \"mutual reachability distances\" to build its MST, which makes it robust to noise and varying densities. Your h3.grid_distance is a purely spatial distance. If you are implementing a true HDBSCAN*, you'd still need to calculate core distances for your H3 cells (perhaps based on the density of PV detections within them) and then compute mutual reachability distances between H3 cells before building the MST.\n",
    "Cluster Stability/Extraction: HDBSCAN*'s dendrogram condensation is a specific algorithm to extract the \"best\" clusters. If you need that level of sophisticated cluster extraction, simply using H3 parent/child relationships might be too simplistic. But for many geospatial analyses, navigating the H3 hierarchy for aggregation is very powerful.\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724db55d",
   "metadata": {
    "editable": true,
    "id": "724db55d",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<figure style=\"text-align: center; margin: 0;\">\n",
    "    <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/parallel_hdbscan_P_GFK_EMST.png?raw=1\" style=\"width:80%;\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b194c",
   "metadata": {
    "editable": true,
    "id": "413b194c",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### How many layers of parallelism can we achieve?\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; align-items: flex-start;\">\n",
    "    <div style=\"flex: 1; padding-right: 20px;\">\n",
    "        <h3 style=\"text-align: center;\">HDBSCAN* Performance Bottlenecks </h3>\n",
    "        <figure style=\"text-align: center; margin-bottom: 20px;\">\n",
    "            <img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/parallel_hdbscan_running_time_decomposition.png?raw=1\" style=\"height:30%;\">\n",
    "            <figcaption align=\"center\" style=\"font-size: 0.8em;\">EO Data complexities</figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "    <div style=\"display: flex; flex-direction: row;\">\n",
    "        <div style=\"flex: 1; padding-bottom: 20px;\">\n",
    "            <h4>Further CPU Optimizations</h4>\n",
    "            <ul>\n",
    "                <li> Reference: <i>\"Optimal Parallel Algorithms for Dendrogram Computation and Single-Linkage Clustering\"</i> (2024)</li>\n",
    "                <li> Even with parallel HDBSCAN*, the dendrogram construction step can remain a significant performance bottleneck.</li>\n",
    "                <li> Presents a a framework for obtaining *merge-based divide-and-conquer algorithms* using tree contractions </li>\n",
    "                <li> O(nlogn) work for previous Single-Linkage Dendrogram (SLD) algorithms </li>\n",
    "                <li> Introduces algorithms with O(nlogh) work, where h is dendrogram height </li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        <div style=\"flex: 1; padding-bottom: 20px;\">\n",
    "            <h4>The Next Frontier: GPU Acceleration</h4>\n",
    "            <ul>\n",
    "                <li> Reference: <i>\"PANDORA: A novel parallel algorithm specifically designed for dendrogram construction on GPUs (and multicore CPUs)\"</i> (2024)</li>\n",
    "                <li> To overcome CPU limitations, especially for highly parallelizable tasks, GPUs offer a further leap in performance. </li>\n",
    "                <li> They present the first known GPU implementation for dendrogram construction. </li>\n",
    "                <li> Uses recursive parallel tree contraction to simplify the MST and computes a dendogram for the output highly-contracted tree </li>\n",
    "                <li> Efficiently expands this \"condensed\" dendrogram by reinserting contracted edges in parallel. </li>\n",
    "                <li> Provides proof that any dendogram construction algorithm requires Ω(nlogn) work, and that **PANDORA achieves this lower bound**. </li>\n",
    "                <li> Their multi-core CPU implementation was twice as fast as SOTA, while the GPU variant achieved a further 15-40×speedup. </li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### **Can we leverage GPU acceleration more broadly in our data science workflows without rewriting everything?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60927501",
   "metadata": {
    "editable": true,
    "id": "60927501",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### MORE Parallelism: Zero-Code-Change GPU Parallelization for DataFrames and Data Science Tools\n",
    "\n",
    "- **What:** A new paradigm for parallelizing data science workloads on GPUs without requiring any code changes by the user.\n",
    "- **Who:** First targeted at common data science libraries like Pandas, NumPy, **scikit-learn**, and Dask.\n",
    "- **How:**\n",
    "    - Not all operations might have GPU-accelerated implementations, but the system will attempt to run operations on the GPU first.\n",
    "    - Some *minor* data prep may be required (converting lists to numpy arrays, working with dataframes, etc.)\n",
    "    - Nvidia RAPIDS ecosystem provides a set of libraries and tools for GPU-accelerated data science and machine learning:\n",
    "        * cuDF: GPU DataFrame library similar to Pandas\n",
    "            - Enables pandas code to run on GPUs with zero code changes.\n",
    "            - Achieved by **loading an extension** (e.g., `%load_ext cudf.pandas` in Jupyter, or `python -m cudf.pandas script.py` for scripts) before importing pandas.\n",
    "            - Compatible with most third-party libraries that operate on pandas objects, accelerating pandas operations even within those libraries.\n",
    "            - Operations are attempted on the GPU first (using cuDF); if an operation is not supported or fails, it automatically falls back to the CPU (using standard pandas). Data synchronization between CPU and GPU memory happens under the hood as needed.\n",
    "        * cuML's `cuml.accel`: GPU-accelerated machine learning library with scikit-learn-like APIs:\n",
    "            - Similar to `cudf.pandas`, allows many of their regression, clustering, and classification estimator classes to be used with cuML's GPU-accelerated implementations.\n",
    "            - Enabled by `%load_ext cuml.accel` or `python -m cuml.accel script.py`.\n",
    "            - Reported speedups: Random Forest ~25x, Linear Regression ~52x, t-SNE ~50x, UMAP ~60x, **HDBSCAN** ~175x.\n",
    "        * cuGraph: GPU-accelerated graph analytics library\n",
    "        * cuSpatial: GPU-accelerated geospatial analytics library\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "<img src=\"https://github.com/avega17/CCOM_MS_Spring_2025_EO_PV_research/blob/main/report/assets/figures/nvidia-cuml-scikit-learn.png?raw=1\" style=\"width:50%;\">\n",
    "<figcaption align = \"center\"> RAPIDS CuML Overview for scikit-learn </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47638a8e",
   "metadata": {
    "editable": true,
    "id": "47638a8e",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Brief Demo of CPU vs GPU HDBSCAN\n",
    "\n",
    "While not quite the [author's implementation](https://github.com/wangyiqiu/hdbscan) of \"Fast Parallel Algorithms for Euclidean MST and Hierarchical Spatial Clustering\", we can still use the RAPIDS cuML library to parallelize [scikit-learn's HDBSCAN implementation](https://github.com/scikit-learn-contrib/hdbscan) on the GPU with zero code changes over our raw data points (instead of H3 grid cells like we proposed above due to time constraints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M_ElJQ_ujdJA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "M_ElJQ_ujdJA",
    "outputId": "3ad3d655-52a0-4cbf-eed1-8fb3c489e505",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6d0a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "8aa6d0a8",
    "outputId": "5f5250da-34fc-4b11-9205-1f0eb4f28553",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "import matplotlib.style as style\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use a clean, professional style for the plot\n",
    "style.use('seaborn-v0_8-whitegrid') # Or 'ggplot', 'seaborn-v0_8-pastel', etc.\n",
    "\n",
    "# tmp cache dir\n",
    "cache_dir = '/content/.cache/hdbscan'\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# --- 2. HDBSCAN Parameters ---\n",
    "# Keep consistent for a fair comparison\n",
    "min_cluster_size = 20\n",
    "min_samples = 5 # Setting min_samples can sometimes offer more nuanced clustering\n",
    "# If using lat/lon, ideally project to planar or use 'haversine' but 'euclidean' on lat/lon is often used for raw speed demos.\n",
    "# metric = 'euclidean' # Ensure this is well-supported by cuML's HDBSCAN for acceleration\n",
    "metric = 'haversine'\n",
    "n_cpus = os.cpu_count() // 2 # Use half the available cores for parallelism\n",
    "algorithm = 'prims_balltree' # options are \"best\", “brute”, “kd_tree”, “ball_tree” for sklearn;\n",
    "# options for hdbscan lib: \"best\", \"generic\", \"prims_kdtree\", \"prims_balltree\", \"boruvka_kdtree\", \"boruvka_balltree\"\n",
    "leaf_size = 100 # Default is 40, but can be adjusted for performance\n",
    "n_jobs = os.cpu_count() # Use all available cores for parallel processing\n",
    "cluster_selection_method = 'eom' # \"Excess of Mass\"\n",
    "epsilon = 100 / 637100 # rough radius of Earth in meters; corresponds to min distance of ~100m to be in same cluster\n",
    "gen_min_span_tree = True\n",
    "sample_size = 50000\n",
    "\n",
    "hdbscan_params = {\n",
    "    'min_cluster_size': min_cluster_size,\n",
    "    'min_samples': min_samples,\n",
    "    'algorithm': algorithm,\n",
    "    'cluster_selection_method': cluster_selection_method,\n",
    "    'cluster_selection_epsilon': epsilon,\n",
    "    'metric': metric,\n",
    "    'gen_min_span_tree': gen_min_span_tree,\n",
    "    'core_dist_n_jobs': n_jobs,\n",
    "    'memory': cache_dir\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e10c29-2251-4965-9915-c34d6153261b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using data previously loaded into ds_gdf\n",
    "coords_df = pd.DataFrame({'latitude': ds_gdf['centroid_lat'], 'longitude': ds_gdf['centroid_lon']})\n",
    "coords_df.dropna(inplace=True) # drop invalid data to avoid errors\n",
    "coords_df = coords_df[~np.isinf(coords_df).any(axis=1)] # remove rows with infinite values\n",
    "data_for_hdbscan = coords_df[['longitude', 'latitude']].to_numpy()\n",
    "# sample 130K points (~1/3 of data) for faster clustering\n",
    "data_for_hdbscan = data_for_hdbscan[np.random.choice(data_for_hdbscan.shape[0], sample_size, replace=False)]\n",
    "\n",
    "if metric == 'haversine':\n",
    "    data_for_hdbscan = np.radians(data_for_hdbscan) # Convert to radians for haversine distance calculation\n",
    "print(f\"Data shape for HDBSCAN: {data_for_hdbscan.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d325d0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "8d325d0d",
    "outputId": "1bc88abe-70b2-4f10-c0a0-e7b7530a06f5",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "process = psutil.Process(os.getpid())\n",
    "mem_before = process.memory_info().rss / (1024 * 1024) # convert to MB\n",
    "start_time = time.time()\n",
    "model = HDBSCAN(**hdbscan_params)\n",
    "%time clusters = model.fit_predict(data_for_hdbscan)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "mem_after = process.memory_info().rss / (1024 * 1024)\n",
    "cpu_memory_change = mem_after - mem_before\n",
    "\n",
    "num_clusters_found = len(np.unique(clusters[clusters != -1])) # Count actual clusters, exclude noise\n",
    "num_noise_points = np.sum(clusters == -1)\n",
    "\n",
    "print(f\"  Execution Time: {elapsed_time:.3f} seconds\")\n",
    "print(f\"  CPU Memory Change: {cpu_memory_change:.2f} MB\")\n",
    "print(f\"  Clusters Found: {num_clusters_found} (excluding noise)\")\n",
    "print(f\"  Noise Points: {num_noise_points}\")\n",
    "benchmark_results = [['HDBSCAN (CPU)', elapsed_time, cpu_memory_change, num_clusters_found, num_noise_points]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gU6xtyZiZ_-H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "gU6xtyZiZ_-H",
    "outputId": "0ea2f65f-a6a1-4227-b7c2-9c420c8a1126",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "# ranges from\n",
    "%time print(silhouette_score(data_for_hdbscan, model.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wwKnzPLqtPkg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "editable": true,
    "id": "wwKnzPLqtPkg",
    "outputId": "3dc5a1e1-a93d-4e21-8866-11fa46a32f82",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import seaborn as sns\n",
    "labels = model.labels_\n",
    "x = data_for_hdbscan[:, 0]\n",
    "y = data_for_hdbscan[:, 1]\n",
    "unique_labels = np.unique(labels)\n",
    "colors = sns.color_palette('viridis', n_colors=len(unique_labels))\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    if label == -1:\n",
    "        # Color for noise points\n",
    "        plt.scatter(data_for_hdbscan[labels == label, 0], data_for_hdbscan[labels == label, 1], color='gray', label='Noise', alpha=0.3, s=10)\n",
    "    else:\n",
    "        plt.scatter(data_for_hdbscan[labels == label, 0], data_for_hdbscan[labels == label, 1], color=colors[i], label=f'Cluster {label}', alpha=0.8, s=15)\n",
    "\n",
    "plt.title('HDBSCAN Clustering Results')\n",
    "plt.xlabel('Longitude (radians)')\n",
    "plt.ylabel('Latitude (radias)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UWPOWowwxE85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "editable": true,
    "id": "UWPOWowwxE85",
    "outputId": "17ac8dca-f662-42c5-964b-98a815b201e6",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HDBSCAN builds a condensed tree representing the hierarchy of clusters. This tree can be visualized as a dendrogram, showing how clusters merge as the density threshold changes.\n",
    "# plot hierarchy of clusters\n",
    "%time model.condensed_tree_.plot(select_clusters=True)\n",
    "plt.title('Condensed Tree of HDBSCAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yjtYKOW-xWTW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "editable": true,
    "id": "yjtYKOW-xWTW",
    "outputId": "1d20ffae-5219-4a31-a697-ceb35fc94961",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install networkx\n",
    "# The MST is used internally by HDBSCAN. Visualizing the MST can help understand how points are connected and how clusters are formed.\n",
    "import networkx as nx\n",
    "mst_sample = 25000\n",
    "sampled_mst = model.minimum_spanning_tree_.to_pandas().sample(mst_sample)\n",
    "G = nx.from_pandas_edgelist(sampled_mst, 'from', 'to', edge_attr='distance')\n",
    "\n",
    "\n",
    "# add back lat lon in degrees\n",
    "hdbscan_viz_df = data_for_hdbscan.copy()\n",
    "hdbscan_viz_df = pd.DataFrame(hdbscan_viz_df, columns=['longitude', 'latitude'])\n",
    "hdbscan_viz_df['latitude_deg'] = np.degrees(hdbscan_viz_df['latitude'])\n",
    "hdbscan_viz_df['longitude_deg'] = np.degrees(hdbscan_viz_df['longitude'])\n",
    "hdbscan_viz_df['cluster'] = model.labels_\n",
    "\n",
    "# Now, use the degree columns for the 'pos' dictionary\n",
    "pos = {}\n",
    "for i, row in hdbscan_viz_df.iterrows():\n",
    "    # Use longitude_deg for x-coordinate and latitude_deg for y-coordinate\n",
    "    pos[i] = (row['longitude_deg'], row['latitude_deg'])\n",
    "\n",
    "# Get edge distances for coloring\n",
    "edge_distances = [data['distance'] for u, v, data in G.edges(data=True)]\n",
    "\n",
    "# Create a colormap based on edge distances\n",
    "cmap = plt.cm.inferno # others include viridis, plasma\n",
    "norm = plt.Normalize(vmin=min(edge_distances), vmax=max(edge_distances))\n",
    "\n",
    "# filter out excessively long edges (e.g. UK <-> South America)\n",
    "distance_threshold = np.percentile(edge_distances, 90) # Example: keep edges below the 90th percentile\n",
    "print(f\"Filtering edges with distance greater than: {distance_threshold:.2f}\")\n",
    "# Create a new graph containing only edges below the threshold\n",
    "filtered_edges = [(u, v, data) for u, v, data in G.edges(data=True) if data['distance'] <= distance_threshold]\n",
    "# Create a new graph starting with all nodes from the original graph\n",
    "G_filtered = nx.Graph()\n",
    "G_filtered.add_nodes_from(G.nodes(data=True))\n",
    "G_filtered.add_edges_from(filtered_edges)\n",
    "# Need to make sure only nodes present in G_filtered are added\n",
    "pos_filtered = pos # {node: pos[node] for node in G_filtered.nodes()}\n",
    "# Get edge distances for the filtered graph (for coloring)\n",
    "filtered_edge_distances = [data['distance'] for u, v, data in G_filtered.edges(data=True)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "nx.draw(G_filtered, pos_filtered, with_labels=False, node_size=5,\n",
    "        edge_color=filtered_edge_distances, edge_cmap=cmap,\n",
    "        width=0.1, alpha=0.3, ax=ax)\n",
    "\n",
    "# Add a colorbar to show the mapping of colors to distances\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "plt.colorbar(sm, ax=ax, label='Distance')\n",
    "\n",
    "plt.title('Minimum Spanning Tree (Geographic Layout) of HDBSCAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ugtjQh4GxwIh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "editable": true,
    "id": "ugtjQh4GxwIh",
    "outputId": "c7c5902a-1296-48dd-cf1a-efb918f3855e",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HDBSCAN assigns a stability score to each cluster, indicating how long the cluster persists across different density levels.\n",
    "# Visualizing these scores can help assess the robustness of the clusters.\n",
    "cluster_stability = model.cluster_persistence_\n",
    "sorted_idx = cluster_stability.argsort()[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(cluster_stability)), cluster_stability[sorted_idx])\n",
    "plt.xticks(range(len(cluster_stability)), sorted_idx, rotation=90)\n",
    "plt.xlabel('Cluster Index')\n",
    "plt.ylabel('Stability Score')\n",
    "plt.title('Cluster Stability Scores')\n",
    "plt.show()\n",
    "# save cpu model for later visualization\n",
    "cpu_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5bf9fd-4a31-4160-a646-85274ba21f26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "0f5bf9fd-4a31-4160-a646-85274ba21f26",
    "outputId": "44908384-f6a8-402b-af04-9b3549a3aec7",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    # load extensions for zero-code change GPU acceleration\n",
    "    %load_ext cuml.accel\n",
    "    %load_ext cudf.pandas\n",
    "    # reimport hdbscan, pandas, and other libraries that may be affected\n",
    "    import pandas as pd\n",
    "    from sklearn.cluster import HDBSCAN\n",
    "\n",
    "    # using data previously loaded into ds_gdf\n",
    "    ds_gdf_lats = ds_gdf['centroid_lat'].to_numpy()\n",
    "    ds_gdf_lons = ds_gdf['centroid_lon'].to_numpy()\n",
    "    coords_df = pd.DataFrame({'latitude': ds_gdf_lats, 'longitude': ds_gdf_lons})\n",
    "    coords_df.dropna(inplace=True) # drop invalid data to avoid errors\n",
    "    coords_df = coords_df[~np.isinf(coords_df).any(axis=1)] # remove rows with infinite values\n",
    "    data_for_hdbscan = coords_df[['longitude', 'latitude']]\n",
    "    # sample 100K points\n",
    "    data_for_hdbscan = data_for_hdbscan.sample(sample_size)\n",
    "    print(f\"Data shape for HDBSCAN: {data_for_hdbscan.shape}\")\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_before = process.memory_info().rss / (1024 * 1024) # convert to MB\n",
    "    start_time = time.time()\n",
    "    hdbscan_params.pop('core_dist_n_jobs')\n",
    "    hdbscan_params.pop('memory')\n",
    "    hdbscan_params.pop('gen_min_span_tree')\n",
    "    hdbscan_params['algorithm'] = 'ball_tree'\n",
    "    model = HDBSCAN(**hdbscan_params)\n",
    "    clusters = model.fit_predict(coords_df)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mem_after = process.memory_info().rss / (1024 * 1024)\n",
    "    cpu_memory_change = mem_after - mem_before\n",
    "\n",
    "    num_clusters_found = len(np.unique(clusters[clusters != -1])) # Count actual clusters, exclude noise\n",
    "    num_noise_points = np.sum(clusters == -1)\n",
    "\n",
    "    print(f\"  Execution Time: {elapsed_time:.3f} seconds\")\n",
    "    print(f\"  CPU Memory Change: {cpu_memory_change:.2f} MB\")\n",
    "    print(f\"  Clusters Found: {num_clusters_found} (excluding noise)\")\n",
    "    print(f\"  Noise Points: {num_noise_points}\")\n",
    "    benchmark_results = [['HDBSCAN (GPU - cuml.accel)', elapsed_time, cpu_memory_change, num_clusters_found, num_noise_points]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oWIIN2dTaQV8",
   "metadata": {
    "id": "oWIIN2dTaQV8"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(silhouette_score(data_for_hdbscan, model.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "APljtVa2uKe5",
   "metadata": {
    "id": "APljtVa2uKe5"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    # Plot the results\n",
    "    labels = model.labels_\n",
    "    x = data_for_hdbscan[:, 0]\n",
    "    y = data_for_hdbscan[:, 1]\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = sns.color_palette('viridis', n_colors=len(unique_labels))\n",
    "\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        if label == -1:\n",
    "            # Color for noise points\n",
    "            plt.scatter(x[labels == label, 0], x[labels == label, 1], color='gray', label='Noise', alpha=0.6)\n",
    "        else:\n",
    "            plt.scatter(x[labels == label, 0], x[labels == label, 1], color=colors[i], label=f'Cluster {label}', alpha=0.2)\n",
    "\n",
    "    plt.title('HDBSCAN Clustering Results')\n",
    "    plt.xlabel('X (lat)')\n",
    "    plt.ylabel('Y (lon)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EOmLOaua0FmH",
   "metadata": {
    "id": "EOmLOaua0FmH"
   },
   "outputs": [],
   "source": [
    "# HDBSCAN builds a condensed tree representing the hierarchy of clusters. This tree can be visualized as a dendrogram, showing how clusters merge as the density threshold changes.\n",
    "# plot hierarchy of clusters\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    model.condensed_tree_.plot(select_clusters=True)\n",
    "    plt.title('Condensed Tree of HDBSCAN')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WKR82BBb0GQl",
   "metadata": {
    "id": "WKR82BBb0GQl"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "# The MST is used internally by HDBSCAN. Visualizing the MST can help understand how points are connected and how clusters are formed.\n",
    "    model.minimum_spanning_tree_.plot(edge_cmap='viridis',\n",
    "                                        edge_clim=(0.0, 1.0),\n",
    "                                        node_size=10,\n",
    "                                        with_labels=False)\n",
    "    plt.title('Minimum Spanning Tree of HDBSCAN')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IJL_ACyC0ITs",
   "metadata": {
    "id": "IJL_ACyC0ITs"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    # HDBSCAN assigns a stability score to each cluster, indicating how long the cluster persists across different density levels.\n",
    "    # Visualizing these scores can help assess the robustness of the clusters.\n",
    "    cluster_stability = model.cluster_persistence_\n",
    "    sorted_idx = cluster_stability.argsort()[::-1]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(cluster_stability)), cluster_stability[sorted_idx])\n",
    "    plt.xticks(range(len(cluster_stability)), sorted_idx, rotation=90)\n",
    "    plt.xlabel('Cluster Index')\n",
    "    plt.ylabel('Stability Score')\n",
    "    plt.title('Cluster Stability Scores')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91b822-c0ef-4a65-a0eb-7733cc50ee27",
   "metadata": {
    "editable": true,
    "id": "2c91b822-c0ef-4a65-a0eb-7733cc50ee27",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(benchmark_results_list) > 0:\n",
    "    df_results = pd.DataFrame(benchmark_results, columns=['Implementation', 'Time (s)', 'CPU Memory Change (MB)', 'Clusters Found', 'Noise Points'])\n",
    "    print(\"\\nBenchmark Summary:\")\n",
    "    print(df_results)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Time Plot\n",
    "    df_results.plot(kind='bar', x='Implementation', y='Time (s)', ax=ax[0], legend=None, color=['skyblue', 'lightcoral'])\n",
    "    ax[0].set_title(f'HDBSCAN Execution Time\\n({data_for_hdbscan.shape[0]} points, min_cluster_size={min_cluster_size})')\n",
    "    ax[0].set_ylabel('Time (seconds)')\n",
    "    ax[0].set_xlabel('')\n",
    "    ax[0].tick_params(axis='x', rotation=0)\n",
    "    for p in ax[0].patches:\n",
    "        ax[0].annotate(f\"{p.get_height():.2f}s\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "    # CPU Memory Change Plot\n",
    "    df_results.plot(kind='bar', x='Implementation', y='CPU Memory Change (MB)', ax=ax[1], legend=None, color=['skyblue', 'lightcoral'])\n",
    "    ax[1].set_title(f'CPU Process Memory Change During HDBSCAN')\n",
    "    ax[1].set_ylabel('Memory Change (MB)')\n",
    "    ax[1].set_xlabel('')\n",
    "    ax[1].tick_params(axis='x', rotation=0)\n",
    "    for p in ax[1].patches:\n",
    "        ax[1].annotate(f\"{p.get_height():.1f}MB\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495e99a-4114-4652-b7ac-55c3301d17bf",
   "metadata": {
    "editable": true,
    "id": "a495e99a-4114-4652-b7ac-55c3301d17bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate and print speedup if both results are available\n",
    "if len(df_results) == 2 and df_results.loc[1, 'Time (s)'] > 0:\n",
    "    cpu_time = df_results.loc[df_results['Implementation'] == 'HDBSCAN (CPU)', 'Time (s)'].iloc[0]\n",
    "    gpu_time = df_results.loc[df_results['Implementation'] == 'HDBSCAN (GPU - cuml.accel)', 'Time (s)'].iloc[0]\n",
    "    if gpu_time > 0: # Avoid division by zero\n",
    "        speedup = cpu_time / gpu_time\n",
    "        print(f\"\\nApproximate Speedup (CPU Time / GPU Time): {speedup:.2f}x\")\n",
    "    else:\n",
    "        print(\"\\nGPU execution time was zero or invalid, cannot calculate speedup.\")\n",
    "\n",
    "    cpu_clusters = df_results.loc[df_results['Implementation'] == 'HDBSCAN (CPU)', 'Clusters Found'].iloc[0]\n",
    "    gpu_clusters = df_results.loc[df_results['Implementation'] == 'HDBSCAN (GPU - cuml.accel)', 'Clusters Found'].iloc[0]\n",
    "    print(f\"Clusters (CPU): {cpu_clusters}, Noise (CPU): {df_results.loc[df_results['Implementation'] == 'HDBSCAN (CPU)', 'Noise Points'].iloc[0]}\")\n",
    "    print(f\"Clusters (GPU): {gpu_clusters}, Noise (GPU): {df_results.loc[df_results['Implementation'] == 'HDBSCAN (GPU - cuml.accel)', 'Noise Points'].iloc[0]}\")\n",
    "    if cpu_clusters == gpu_clusters:\n",
    "        print(\"Cluster counts (excluding noise) match.\")\n",
    "    else:\n",
    "        print(\"WARNING: Cluster counts (excluding noise) DO NOT match. Results may differ due to precision or implementation specifics.\")\n",
    "else:\n",
    "    print(\"No benchmark results to plot. Check for errors during execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795ca3f-8072-4164-a971-2f8b2241e1bb",
   "metadata": {
    "editable": true,
    "id": "d795ca3f-8072-4164-a971-2f8b2241e1bb",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Application to PV Array Analysis: Next steps & Future work\n",
    "\n",
    "* Dataset preparation and augmentation work demoed here\n",
    "    * Further augmenting with remaining datasets\n",
    "- Initial Clustering results with preliminary dataset and h3 using easily available `scikit-learn` implementations + GPU acceleration (report)\n",
    "    - Explore use of HDBSCAN* for parallel EMST construction (Summer)\n",
    "- More dataset prep work: STAC + Virtual Raster Datasets\n",
    "    - Testing STAC query performance improvements (Summer)\n",
    "- Further explore idea of H3 + Hiearchical Spatial Clustering for Open Dataset distribution\n",
    "- Scaling to the cloud (Thesis work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425d0df",
   "metadata": {
    "editable": true,
    "id": "9425d0df",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "## “The history of programming languages is full of tasks that programmers did manually until we learned to create language constructs and compilers that could do these automatically. It would be nice if we could do the same here to reduce the burden of writing such programs.”\n",
    "### — Shriram Krishnamurthi, author of Programming Languages: Application and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d1b3d",
   "metadata": {
    "editable": true,
    "id": "242d1b3d",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# ¡Gracias por su atención!\n",
    "## ¿Preguntas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v_lL6dNdwkXg",
   "metadata": {
    "id": "v_lL6dNdwkXg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "eo-pv-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05bf66a5af2f4f28b77482319412b3ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "button_style": "danger",
       "description": "Remove Dataset",
       "layout": "IPY_MODEL_beb1757dcf8041b2a25a64acf47bcc2d",
       "style": "IPY_MODEL_b89b1fa239304089b0d82e4a9fb2faad",
       "tooltip": null
      }
     },
     "0bd1fd182cc3431ea94115bb86e9518b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_58e0b5df2e284a35bf42822781b68fb7",
       "style": "IPY_MODEL_191e23e318e848d8b58bca7a8664e708",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>https://github.com/qingfengxitu/ChinaPV/tree/main</td></tr>\n        <tr><td>Repository</td><td>github</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>shp</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>3356</td></tr>\n    </table>\n    "
      }
     },
     "0c68bc07da5848c0852ecccddae7af2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2f29121e02984167ab4e154efce5c488",
        "IPY_MODEL_fe2701cce4974e8b8e11c09c42f5be65",
        "IPY_MODEL_05bf66a5af2f4f28b77482319412b3ee"
       ],
       "layout": "IPY_MODEL_6dee658960f0468c823204d7bf71e453"
      }
     },
     "0ed2ded55c284312ac54f934603159dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3e5980eb6fb444559817cdbf49d0ec17",
       "style": "IPY_MODEL_1a92362c5a854f6fb8a4e11c67a10137",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.5281/zenodo.8038684</td></tr>\n        <tr><td>Repository</td><td>sciencebase</td></tr>\n        <tr><td>Compression</td><td>zip</td></tr>\n        <tr><td>Label Format</td><td>shp</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>4186</td></tr>\n    </table>\n    "
      }
     },
     "0fc9e16c80e4495f9dd9ea6c6b6f806f": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_938dcd3c355d43e6acdb39e168d9d3bb",
       "outputs": [
        {
         "data": {
          "application/vnd.jupyter.widget-view+json": {
           "model_id": "9e31f75cbdaa4cfb9d85e12224484807",
           "version_major": 2,
           "version_minor": 0
          },
          "text/plain": "HBox(children=(Dropdown(description='Dataset:', layout=Layout(margin='20 20 auto 20 20', width='70%'), options…"
         },
         "metadata": {},
         "output_type": "display_data"
        },
        {
         "data": {
          "application/vnd.jupyter.widget-view+json": {
           "model_id": "8daf1a31f1a34fb2a31ad65c29b15a86",
           "version_major": 2,
           "version_minor": 0
          },
          "text/plain": "Accordion(children=(HTML(value='\\n    <style>\\n    .dataset-table {\\n        border-collapse: collapse;\\n     …"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "1052498531f14193b077b2e6bb65459e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_430fe784e364481b915f0420a9a9c2d2",
       "style": "IPY_MODEL_238f38c93cf9422eafa74be924eaa0d7",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.5281/zenodo.4059881</td></tr>\n        <tr><td>Repository</td><td>zenodo</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>geojson</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>265418</td></tr>\n    </table>\n    "
      }
     },
     "14a198dd302141978498c0185746205e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "16ca3d3bd293460484aaa21ede1f590d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "191e23e318e848d8b58bca7a8664e708": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1a92362c5a854f6fb8a4e11c67a10137": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1b2b83cd41c246a69dfa5ea2c79ae637": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "bar_color": "black",
       "description_width": ""
      }
     },
     "1d2ab4d9dd054e4c9f66698abec8277c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7968f63825354f49b6db7d9d09bf7d07",
       "style": "IPY_MODEL_41d545e8cc7b47038081d674ec3c7f4c",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.5281/zenodo.4059881</td></tr>\n        <tr><td>Repository</td><td>zenodo</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>geojson</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>265418</td></tr>\n    </table>\n    "
      }
     },
     "21adedefc4464f8f878e6687e801d7a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "238f38c93cf9422eafa74be924eaa0d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "24bcfdcc23164ade9f6c328f4eb22029": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "282f39c130ae486e88d4a969239ff36d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8f164aabb7194bf7b407472624c4324c",
       "style": "IPY_MODEL_c5d557b86b284875a019e2df7ae0c401",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.6084/m9.figshare.11310269.v6</td></tr>\n        <tr><td>Repository</td><td>figshare</td></tr>\n        <tr><td>Compression</td><td>zip</td></tr>\n        <tr><td>Label Format</td><td>gpkg</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>35272</td></tr>\n    </table>\n    "
      }
     },
     "2f29121e02984167ab4e154efce5c488": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DropdownModel",
      "state": {
       "_options_labels": [
        "deu_maxar_vhr_2023",
        "uk_crowdsourced_pv_2020",
        "usa_eia_large_scale_pv_2023",
        "chn_med_res_pv_2024",
        "usa_cali_usgs_pv_2016",
        "chn_jiangsu_vhr_pv_2021",
        "ind_pv_solar_farms_2022",
        "fra_west_eur_pv_installations_2023",
        "global_pv_inventory_sent2_spot_2021",
        "global_pv_inventory_sent2_2024",
        "global_harmonized_large_solar_farms_2020"
       ],
       "description": "Dataset:",
       "index": 0,
       "layout": "IPY_MODEL_ffb36f4903cd4aea93a96e3d1aa96c20",
       "style": "IPY_MODEL_4a6f42dc0c37474586690fdb08f68c57"
      }
     },
     "34f28fc115fc4f44a3bb540942c0b038": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "36593dbca569442fa5f0679bbb761865": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_99286c15cadb43f29c6d17da46584588",
       "style": "IPY_MODEL_3aa72315344e414d8f45e4f7fd7e285d",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>https://github.com/qingfengxitu/ChinaPV/tree/main</td></tr>\n        <tr><td>Repository</td><td>github</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>shp</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>3356</td></tr>\n    </table>\n    "
      }
     },
     "38741141cb7349d99ba12e26fa4327eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "margin": "0 auto",
       "width": "50%"
      }
     },
     "3aa72315344e414d8f45e4f7fd7e285d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3e4b8d42a25646a7b503df607add3455": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3e5980eb6fb444559817cdbf49d0ec17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4031369d8827432885d20ac2c12b8289": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "41d545e8cc7b47038081d674ec3c7f4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "430fe784e364481b915f0420a9a9c2d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "46da12f9ee014b0dbd8ddbbccb8ab03e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4a6f42dc0c37474586690fdb08f68c57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4b4b1438aaf7490cb75d24ea02fd52cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_d71676a5a596481cb6715468c170d6c1",
       "style": "IPY_MODEL_1b2b83cd41c246a69dfa5ea2c79ae637",
       "value": 100
      }
     },
     "4dc80495e677423dbdd8e7a03a503d15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4031369d8827432885d20ac2c12b8289",
       "style": "IPY_MODEL_7ae51e143919495c9fb549b80144834e",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.6084/m9.figshare.22081091.v3</td></tr>\n        <tr><td>Repository</td><td>figshare</td></tr>\n        <tr><td>Compression</td><td>zip</td></tr>\n        <tr><td>Label Format</td><td>yolo_fmt_txt</td></tr>\n        <tr><td>Has Images</td><td>True</td></tr>\n        <tr><td>Label Count</td><td>2542</td></tr>\n    </table>\n    "
      }
     },
     "4e2e09511faa496ca74fc27dd1b8e139": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fa410fa6c4b84bf39a356d0d2f7669e0",
       "style": "IPY_MODEL_aaa6abb911d34f06ad9d44a2b68547c6",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.6084/m9.figshare.11310269.v6</td></tr>\n        <tr><td>Repository</td><td>figshare</td></tr>\n        <tr><td>Compression</td><td>zip</td></tr>\n        <tr><td>Label Format</td><td>gpkg</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>35272</td></tr>\n    </table>\n    "
      }
     },
     "57ddd9ecd65148fea5ec42014c5b12d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_21adedefc4464f8f878e6687e801d7a7",
       "style": "IPY_MODEL_8797039731fa4a2496fad01b1b7a964b",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.5281/zenodo.5005867</td></tr>\n        <tr><td>Repository</td><td>zenodo</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>geojson</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>[50426, 68661]</td></tr>\n    </table>\n    "
      }
     },
     "5887580ab52a434eba55b52109a0d093": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a06ae06ab9794cde9e107a0fc6657fec",
       "style": "IPY_MODEL_5abb119e15a3456f8de6fc8650a07a8b",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.5281/zenodo.8038684</td></tr>\n        <tr><td>Repository</td><td>sciencebase</td></tr>\n        <tr><td>Compression</td><td>zip</td></tr>\n        <tr><td>Label Format</td><td>shp</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>4186</td></tr>\n    </table>\n    "
      }
     },
     "58e0b5df2e284a35bf42822781b68fb7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5abb119e15a3456f8de6fc8650a07a8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "668c028252d84e91a05a5d22a5ee3953": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6acb56e1472e40bf92ba47b95bfd2aa9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "6c2056728bb241b3a953233e50ac8704": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6dee658960f0468c823204d7bf71e453": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6f4a284bb3f24363ae1d27c254d0d43a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "margin": "20 20 auto 20 20",
       "width": "70%"
      }
     },
     "750a53d5b86d4950a2d4bc07933129ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7968f63825354f49b6db7d9d09bf7d07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "79fd48827da3463facec605fa5cdd24b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7a27c4d7c6914607845541693dc5b10e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_16ca3d3bd293460484aaa21ede1f590d",
       "style": "IPY_MODEL_b7927d54a5e24d038fa57d68953e843f",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.5281/zenodo.5005867</td></tr>\n        <tr><td>Repository</td><td>zenodo</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>geojson</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>[50426, 68661]</td></tr>\n    </table>\n    "
      }
     },
     "7ae51e143919495c9fb549b80144834e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7cc71a1cbdc747e885e39373a34fed50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7cd02d8d30144265b18c206ff57187f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_24bcfdcc23164ade9f6c328f4eb22029",
       "style": "IPY_MODEL_90192f659eff4eb7b015fb127333f1ac",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>https://github.com/yzyly1992/GloSoFarID/tree/main/data_coordinates</td></tr>\n        <tr><td>Repository</td><td>github</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>json</td></tr>\n        <tr><td>Has Images</td><td>True</td></tr>\n        <tr><td>Label Count</td><td>6793</td></tr>\n    </table>\n    "
      }
     },
     "7f6ff44f404b417b95d0768b1ed367da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "8797039731fa4a2496fad01b1b7a964b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8daf1a31f1a34fb2a31ad65c29b15a86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "AccordionModel",
      "state": {
       "children": [
        "IPY_MODEL_4e2e09511faa496ca74fc27dd1b8e139",
        "IPY_MODEL_7cd02d8d30144265b18c206ff57187f7",
        "IPY_MODEL_7a27c4d7c6914607845541693dc5b10e",
        "IPY_MODEL_a1b4d772ea7a47f896defb16a3e34e8a",
        "IPY_MODEL_ec02c51063b44c90a7feb094fa7d7a30",
        "IPY_MODEL_f983321dadc94d7ab53260edda9f64e8",
        "IPY_MODEL_0bd1fd182cc3431ea94115bb86e9518b",
        "IPY_MODEL_0ed2ded55c284312ac54f934603159dd",
        "IPY_MODEL_1d2ab4d9dd054e4c9f66698abec8277c",
        "IPY_MODEL_cb96caa9e0c3414db1d997dc24cdefcc"
       ],
       "layout": "IPY_MODEL_38741141cb7349d99ba12e26fa4327eb",
       "titles": [
        "global_harmonized_large_solar_farms_2020",
        "global_pv_inventory_sent2_2024",
        "global_pv_inventory_sent2_spot_2021",
        "fra_west_eur_pv_installations_2023",
        "ind_pv_solar_farms_2022",
        "usa_cali_usgs_pv_2016",
        "chn_med_res_pv_2024",
        "usa_eia_large_scale_pv_2023",
        "uk_crowdsourced_pv_2020",
        "deu_maxar_vhr_2023"
       ]
      }
     },
     "8f164aabb7194bf7b407472624c4324c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "90192f659eff4eb7b015fb127333f1ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "919b28a507cb48329e2fecc2338ee61c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "91a5be705ed44b189e819e23ceeb3d47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_14a198dd302141978498c0185746205e",
       "style": "IPY_MODEL_a84aeb7926ea48ed85d0a589d89d73b6",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.6084/m9.figshare.3385780.v4</td></tr>\n        <tr><td>Repository</td><td>figshare</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>geojson</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>19433</td></tr>\n    </table>\n    "
      }
     },
     "938dcd3c355d43e6acdb39e168d9d3bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "93eb7e4ee7314a1d9fbce466cb2d095b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DropdownModel",
      "state": {
       "_options_labels": [
        "deu_maxar_vhr_2023",
        "uk_crowdsourced_pv_2020",
        "usa_eia_large_scale_pv_2023",
        "chn_med_res_pv_2024",
        "usa_cali_usgs_pv_2016",
        "chn_jiangsu_vhr_pv_2021",
        "ind_pv_solar_farms_2022",
        "fra_west_eur_pv_installations_2023",
        "global_pv_inventory_sent2_spot_2021",
        "global_pv_inventory_sent2_2024",
        "global_harmonized_large_solar_farms_2020"
       ],
       "description": "Dataset:",
       "index": 0,
       "layout": "IPY_MODEL_6f4a284bb3f24363ae1d27c254d0d43a",
       "style": "IPY_MODEL_eaaa5f0d76b04f8a8cde317f8f5ce7b1"
      }
     },
     "99286c15cadb43f29c6d17da46584588": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9e31f75cbdaa4cfb9d85e12224484807": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_93eb7e4ee7314a1d9fbce466cb2d095b",
        "IPY_MODEL_bb7804257642430ea69594ba8b44e98f",
        "IPY_MODEL_fb9ae41fabdf424683148f1b672cf657"
       ],
       "layout": "IPY_MODEL_34f28fc115fc4f44a3bb540942c0b038"
      }
     },
     "a06ae06ab9794cde9e107a0fc6657fec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a1b4d772ea7a47f896defb16a3e34e8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_919b28a507cb48329e2fecc2338ee61c",
       "style": "IPY_MODEL_750a53d5b86d4950a2d4bc07933129ac",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.5281/zenodo.6865878</td></tr>\n        <tr><td>Repository</td><td>zenodo</td></tr>\n        <tr><td>Compression</td><td>zip</td></tr>\n        <tr><td>Label Format</td><td>json</td></tr>\n        <tr><td>Has Images</td><td>True</td></tr>\n        <tr><td>Label Count</td><td>[13303, 7686]</td></tr>\n    </table>\n    "
      }
     },
     "a7f7971aead643479cadeeb484728903": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a84aeb7926ea48ed85d0a589d89d73b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aa99cdbe6c684c2cbb4a4001df6d8c65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_aaf4de044bd346f4950cd091a579f41d",
       "style": "IPY_MODEL_db6f3dc8e9ee4da58b384f74a5904006",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>https://raw.githubusercontent.com/microsoft/solar-farms-mapping/refs/heads/main/data/solar_farms_india_2021_merged_simplified.geojson</td></tr>\n        <tr><td>Repository</td><td>github</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>geojson</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>117</td></tr>\n    </table>\n    "
      }
     },
     "aaa6abb911d34f06ad9d44a2b68547c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aadcc0f268c24ba6981ca8adcd29f8ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ea0a17fe26344ff689cdb670c142665e",
       "style": "IPY_MODEL_79fd48827da3463facec605fa5cdd24b",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.5281/zenodo.6865878</td></tr>\n        <tr><td>Repository</td><td>zenodo</td></tr>\n        <tr><td>Compression</td><td>zip</td></tr>\n        <tr><td>Label Format</td><td>json</td></tr>\n        <tr><td>Has Images</td><td>True</td></tr>\n        <tr><td>Label Count</td><td>[13303, 7686]</td></tr>\n    </table>\n    "
      }
     },
     "aaf4de044bd346f4950cd091a579f41d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ac48568a3fb2438b940046e5b361b817": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "b062881acafb42678631b80f88099070": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "margin": "0 auto",
       "width": "50%"
      }
     },
     "b7927d54a5e24d038fa57d68953e843f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b89b1fa239304089b0d82e4a9fb2faad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "bb7804257642430ea69594ba8b44e98f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "button_style": "success",
       "description": "Add Dataset",
       "layout": "IPY_MODEL_eae73d1f2c864b52be85ee6a5bbc5eff",
       "style": "IPY_MODEL_ac48568a3fb2438b940046e5b361b817",
       "tooltip": null
      }
     },
     "beb1757dcf8041b2a25a64acf47bcc2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c039b4eebdce4dcebe063d3fccdc2db6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c11fbd19cb564a7193e61aa626facd2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d5e188d23f674dc1b5a34c848c6956ae",
       "style": "IPY_MODEL_c039b4eebdce4dcebe063d3fccdc2db6",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>https://github.com/yzyly1992/GloSoFarID/tree/main/data_coordinates</td></tr>\n        <tr><td>Repository</td><td>github</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>json</td></tr>\n        <tr><td>Has Images</td><td>True</td></tr>\n        <tr><td>Label Count</td><td>6793</td></tr>\n    </table>\n    "
      }
     },
     "c5d557b86b284875a019e2df7ae0c401": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb96caa9e0c3414db1d997dc24cdefcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_668c028252d84e91a05a5d22a5ee3953",
       "style": "IPY_MODEL_7cc71a1cbdc747e885e39373a34fed50",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.6084/m9.figshare.22081091.v3</td></tr>\n        <tr><td>Repository</td><td>figshare</td></tr>\n        <tr><td>Compression</td><td>zip</td></tr>\n        <tr><td>Label Format</td><td>yolo_fmt_txt</td></tr>\n        <tr><td>Has Images</td><td>True</td></tr>\n        <tr><td>Label Count</td><td>2542</td></tr>\n    </table>\n    "
      }
     },
     "d5e188d23f674dc1b5a34c848c6956ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d71676a5a596481cb6715468c170d6c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "auto"
      }
     },
     "db6f3dc8e9ee4da58b384f74a5904006": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e6bd0bb7e3a0416d8f9698f8a32e21b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "AccordionModel",
      "state": {
       "children": [
        "IPY_MODEL_282f39c130ae486e88d4a969239ff36d",
        "IPY_MODEL_c11fbd19cb564a7193e61aa626facd2a",
        "IPY_MODEL_57ddd9ecd65148fea5ec42014c5b12d0",
        "IPY_MODEL_aadcc0f268c24ba6981ca8adcd29f8ee",
        "IPY_MODEL_aa99cdbe6c684c2cbb4a4001df6d8c65",
        "IPY_MODEL_91a5be705ed44b189e819e23ceeb3d47",
        "IPY_MODEL_36593dbca569442fa5f0679bbb761865",
        "IPY_MODEL_5887580ab52a434eba55b52109a0d093",
        "IPY_MODEL_1052498531f14193b077b2e6bb65459e",
        "IPY_MODEL_4dc80495e677423dbdd8e7a03a503d15"
       ],
       "layout": "IPY_MODEL_b062881acafb42678631b80f88099070",
       "selected_index": 1,
       "titles": [
        "global_harmonized_large_solar_farms_2020",
        "global_pv_inventory_sent2_2024",
        "global_pv_inventory_sent2_spot_2021",
        "fra_west_eur_pv_installations_2023",
        "ind_pv_solar_farms_2022",
        "usa_cali_usgs_pv_2016",
        "chn_med_res_pv_2024",
        "usa_eia_large_scale_pv_2023",
        "uk_crowdsourced_pv_2020",
        "deu_maxar_vhr_2023"
       ]
      }
     },
     "ea0a17fe26344ff689cdb670c142665e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eaaa5f0d76b04f8a8cde317f8f5ce7b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "eae73d1f2c864b52be85ee6a5bbc5eff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec02c51063b44c90a7feb094fa7d7a30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6c2056728bb241b3a953233e50ac8704",
       "style": "IPY_MODEL_a7f7971aead643479cadeeb484728903",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>https://raw.githubusercontent.com/microsoft/solar-farms-mapping/refs/heads/main/data/solar_farms_india_2021_merged_simplified.geojson</td></tr>\n        <tr><td>Repository</td><td>github</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>geojson</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>117</td></tr>\n    </table>\n    "
      }
     },
     "f032e91181404c7385997cbbd85d43c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f983321dadc94d7ab53260edda9f64e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3e4b8d42a25646a7b503df607add3455",
       "style": "IPY_MODEL_46da12f9ee014b0dbd8ddbbccb8ab03e",
       "value": "\n    <style>\n    .dataset-table {\n        border-collapse: collapse;\n        width: 30%;\n        margin: 20px auto;\n        font-family: Arial, sans-serif;\n    }\n    .dataset-table th, .dataset-table td {\n        border: 1px solid #ddd;\n        padding: 8px;\n        text-align: left;\n    }\n    .dataset-table th {\n        background-color: #f2f2f2;\n        font-weight: bold;\n    }\n    </style>\n    <table class=\"dataset-table\">\n        <tr><th>Metadata</th><th>Value</th></tr>\n        <tr><td>DOI/URL</td><td>10.6084/m9.figshare.3385780.v4</td></tr>\n        <tr><td>Repository</td><td>figshare</td></tr>\n        <tr><td>Compression</td><td>None</td></tr>\n        <tr><td>Label Format</td><td>geojson</td></tr>\n        <tr><td>Has Images</td><td>False</td></tr>\n        <tr><td>Label Count</td><td>19433</td></tr>\n    </table>\n    "
      }
     },
     "fa410fa6c4b84bf39a356d0d2f7669e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa5162401bb94ffeaa92d1ea352da7cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fb9ae41fabdf424683148f1b672cf657": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "button_style": "danger",
       "description": "Remove Dataset",
       "layout": "IPY_MODEL_f032e91181404c7385997cbbd85d43c3",
       "style": "IPY_MODEL_7f6ff44f404b417b95d0768b1ed367da",
       "tooltip": null
      }
     },
     "fe2701cce4974e8b8e11c09c42f5be65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "button_style": "success",
       "description": "Add Dataset",
       "layout": "IPY_MODEL_fa5162401bb94ffeaa92d1ea352da7cb",
       "style": "IPY_MODEL_6acb56e1472e40bf92ba47b95bfd2aa9",
       "tooltip": null
      }
     },
     "ffb36f4903cd4aea93a96e3d1aa96c20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "margin": "20 20 auto 20 20",
       "width": "70%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
